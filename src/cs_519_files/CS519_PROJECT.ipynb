{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS519_PROJECT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b52410fb7974f078f0ffce82f6c2530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_583f30bb3bc4412c95f6aec8cf52f2ec",
              "IPY_MODEL_0c9cac3a4e2849cbbe637e87650b2ac3"
            ],
            "layout": "IPY_MODEL_dd19dfafdf414b19b60acd240a98b090"
          }
        },
        "583f30bb3bc4412c95f6aec8cf52f2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f393e42a2eae44e3a09f819d2d1511ea",
            "placeholder": "​",
            "style": "IPY_MODEL_89a6857ad4ee44c5a0bc35d4eb60dfe2",
            "value": "0.139 MB of 0.139 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0c9cac3a4e2849cbbe637e87650b2ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c6d9e1214149ae9b7361e92b803355",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c049f13e18884026be208d6599c2099b",
            "value": 1
          }
        },
        "dd19dfafdf414b19b60acd240a98b090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f393e42a2eae44e3a09f819d2d1511ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a6857ad4ee44c5a0bc35d4eb60dfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45c6d9e1214149ae9b7361e92b803355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c049f13e18884026be208d6599c2099b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDoeCD8rP3Em",
        "outputId": "c20c0687-9bfe-4f1f-bb29-03ac5628c806"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.68-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 29 kB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.68 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsZ-dHqI23rL",
        "outputId": "cddac894-32db-4861-882e-2e6586c8e751"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.10.8)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17416 sha256=3e8e4985a215dcee4e6da7e6658a5f64327f25c77858a4e54c84149bc39f75cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq"
      ],
      "metadata": {
        "id": "mn4r-AftMVOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd51f8ff-2138-4976-de61-7142d55d403d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBInDyF1TbFi",
        "outputId": "f20a6d73-9313-47d0-d765-70460dfe7d48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.46\n",
            "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 37.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 18.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.46->boto3) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.46 botocore-1.24.46 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U easynmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v65oQ9Roo1wy",
        "outputId": "a8741bee-879c-4e93-90da-8f88d8bacbc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easynmt\n",
            "  Downloading EasyNMT-2.0.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from easynmt) (4.64.0)\n",
            "Collecting transformers<5,>=4.4\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from easynmt) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easynmt) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from easynmt) (3.2.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from easynmt) (0.1.96)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->easynmt) (4.1.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (0.0.49)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=4.4->easynmt) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5,>=4.4->easynmt) (3.0.8)\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext->easynmt) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=4.4->easynmt) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->easynmt) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=4.4->easynmt) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=4.4->easynmt) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=4.4->easynmt) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=4.4->easynmt) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=4.4->easynmt) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=4.4->easynmt) (7.1.2)\n",
            "Building wheels for collected packages: easynmt, fasttext\n",
            "  Building wheel for easynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easynmt: filename=EasyNMT-2.0.1-py3-none-any.whl size=15447 sha256=b267345b190c561f785d40949da37bf90fd0fb8e360c34af1bad29a86f9426d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/42/fb/b7711d3296456d5f74e6e265dbdb0e3142158f1bb50382caef\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3140867 sha256=b46c505e2b3c25a7f2083a499a0a18784e8b1d42e946b4413fb40adf5c686642\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built easynmt fasttext\n",
            "Installing collected packages: pyyaml, tokenizers, pybind11, huggingface-hub, transformers, fasttext, easynmt\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed easynmt-2.0.1 fasttext-0.9.2 huggingface-hub-0.5.1 pybind11-2.9.2 pyyaml-6.0 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uAxrs1T5c4FG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import wandb\n",
        "\n",
        "from easynmt import EasyNMT\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import contractions                                 # Expanding contractions\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.legacy import data\n",
        "from googletrans import Translator\n",
        "\n",
        "import random\n",
        "import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBQCKvKUQGvt",
        "outputId": "6ddf13b7-d928-4701-d491-18b4d6495a9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' ------------------------------------------')\n",
        "print('| Classifying Gender Dysphoria Disclosures |')\n",
        "print('|  on Social Media with Machine Learning.  |')\n",
        "print(' ------------------------------------------')\n",
        "print()\n",
        "print('Team members:    Cory J. Cascalheira')\n",
        "print('                 Ivan Nieto Gomez   ')\n",
        "print('                 Edgar Corrales Sotelo')\n",
        "print()\n",
        "print('Data Processing....')\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM1VF6QMdFxl",
        "outputId": "9ad72d0c-fb76-478d-b888-2683d0b5d613"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ------------------------------------------\n",
            "| Classifying Gender Dysphoria Disclosures |\n",
            "|  on Social Media with Machine Learning.  |\n",
            " ------------------------------------------\n",
            "\n",
            "Team members:    Cory J. Cascalheira\n",
            "                 Ivan Nieto Gomez   \n",
            "                 Edgar Corrales Sotelo\n",
            "\n",
            "Data Processing....\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#num_of_lines = 2\n",
        "\n",
        "dataset = pd.read_csv('df_truth.csv')\n",
        "dataset.tail()\n",
        "#print('Dataset size: ',dataset.shape)\n",
        "# ------ ORIGINAL DATA --------\n",
        "#print('Original Dataset: \\n',dataset)\n",
        "headers = list(dataset.columns.values)\n",
        "#print(headers)\n",
        "\n",
        "text = dataset.iloc[:,1]            # text = dataset['text']\n",
        "#print(text.shape)\n",
        "#print(text)"
      ],
      "metadata": {
        "id": "NsvF4ViyebAk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "B8EOlNF8vgnX",
        "outputId": "b97bc60e-d5d2-4d31-a795-d67853f511f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      temp_id                                               text  dysphoria  \\\n",
              "0           1  cyclical dysphoria cw: menstruation  hi there,...          1   \n",
              "1           2  idk what to title this but pls give me advice ...          1   \n",
              "2           3  hi there...advice please? i'm new to this comm...          1   \n",
              "3           4  please help i don’t know if this is the right ...          1   \n",
              "4           5  i feel like i'm pretty complicated and it's ki...          0   \n",
              "...       ...                                                ...        ...   \n",
              "1886     1887  coping without hrt is it possible? do i have t...          1   \n",
              "1887     1888  is it possible to feel gender dysphoria but i ...          1   \n",
              "1888     1889  are there upper and lower limits for the wavel...          0   \n",
              "1889     1890  very confused to start i am a 22 yr old afab n...          1   \n",
              "1890     1891  what amount of the formation of organisms is d...          0   \n",
              "\n",
              "      sentiment_valence   WC  Analytic  Clout  Authentic   Tone    WPS  ...  \\\n",
              "0                   -21  208     11.20   3.05      93.91  25.77  13.00  ...   \n",
              "1                   -26  181     10.29  39.11      70.95  35.42  20.11  ...   \n",
              "2                   -30  164      3.85  11.14      96.26  10.40  23.43  ...   \n",
              "3                   -52  254      1.30   2.49      98.33   1.00  23.09  ...   \n",
              "4                   -12   94     12.24   5.55      71.83  93.02   9.40  ...   \n",
              "...                 ...  ...       ...    ...        ...    ...    ...  ...   \n",
              "1886                -11  117     28.12   3.66      82.02   2.70   9.75  ...   \n",
              "1887                 -7   98      8.92  13.08      92.38  25.77  10.89  ...   \n",
              "1888                 -5   21     68.29  82.96      37.24   1.00  10.50  ...   \n",
              "1889                -24  299      6.83  13.49      81.69  16.24  18.69  ...   \n",
              "1890                 -2   92     65.91  74.30       1.00  45.75  30.67  ...   \n",
              "\n",
              "      Colon  SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \\\n",
              "0      0.48    0.0   1.44     0.0  0.00   0.96     5.77     0.00    1.44   \n",
              "1      0.00    0.0   1.10     0.0  0.00   2.21     5.52     3.31    0.55   \n",
              "2      0.00    0.0   0.61     0.0  0.00   0.00     6.10     0.00    0.00   \n",
              "3      0.00    0.0   0.00     0.0  0.00   0.00     4.33     1.57    0.39   \n",
              "4      0.00    0.0   2.13     0.0  0.00   0.00     6.38     2.13    0.00   \n",
              "...     ...    ...    ...     ...   ...    ...      ...      ...     ...   \n",
              "1886   0.00    0.0   3.42     0.0  0.85   0.00     6.84     0.00    0.00   \n",
              "1887   0.00    0.0   2.04     0.0  1.02   0.00     0.00     0.00    0.00   \n",
              "1888   0.00    0.0   9.52     0.0  0.00   0.00     0.00     0.00    0.00   \n",
              "1889   0.00    0.0   0.00     0.0  0.00   0.00     4.68     0.00    0.67   \n",
              "1890   1.09    0.0   1.09     0.0  0.00   0.00     0.00     0.00    0.00   \n",
              "\n",
              "      ngrams  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "...      ...  \n",
              "1886       1  \n",
              "1887       1  \n",
              "1888       0  \n",
              "1889       1  \n",
              "1890       1  \n",
              "\n",
              "[1891 rows x 98 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50733e33-eb41-4f85-adb3-d4639982db16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp_id</th>\n",
              "      <th>text</th>\n",
              "      <th>dysphoria</th>\n",
              "      <th>sentiment_valence</th>\n",
              "      <th>WC</th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Clout</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>...</th>\n",
              "      <th>Colon</th>\n",
              "      <th>SemiC</th>\n",
              "      <th>QMark</th>\n",
              "      <th>Exclam</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Apostro</th>\n",
              "      <th>Parenth</th>\n",
              "      <th>OtherP</th>\n",
              "      <th>ngrams</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cyclical dysphoria cw: menstruation  hi there,...</td>\n",
              "      <td>1</td>\n",
              "      <td>-21</td>\n",
              "      <td>208</td>\n",
              "      <td>11.20</td>\n",
              "      <td>3.05</td>\n",
              "      <td>93.91</td>\n",
              "      <td>25.77</td>\n",
              "      <td>13.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>idk what to title this but pls give me advice ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-26</td>\n",
              "      <td>181</td>\n",
              "      <td>10.29</td>\n",
              "      <td>39.11</td>\n",
              "      <td>70.95</td>\n",
              "      <td>35.42</td>\n",
              "      <td>20.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.21</td>\n",
              "      <td>5.52</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>hi there...advice please? i'm new to this comm...</td>\n",
              "      <td>1</td>\n",
              "      <td>-30</td>\n",
              "      <td>164</td>\n",
              "      <td>3.85</td>\n",
              "      <td>11.14</td>\n",
              "      <td>96.26</td>\n",
              "      <td>10.40</td>\n",
              "      <td>23.43</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>please help i don’t know if this is the right ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-52</td>\n",
              "      <td>254</td>\n",
              "      <td>1.30</td>\n",
              "      <td>2.49</td>\n",
              "      <td>98.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>23.09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>i feel like i'm pretty complicated and it's ki...</td>\n",
              "      <td>0</td>\n",
              "      <td>-12</td>\n",
              "      <td>94</td>\n",
              "      <td>12.24</td>\n",
              "      <td>5.55</td>\n",
              "      <td>71.83</td>\n",
              "      <td>93.02</td>\n",
              "      <td>9.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.38</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1886</th>\n",
              "      <td>1887</td>\n",
              "      <td>coping without hrt is it possible? do i have t...</td>\n",
              "      <td>1</td>\n",
              "      <td>-11</td>\n",
              "      <td>117</td>\n",
              "      <td>28.12</td>\n",
              "      <td>3.66</td>\n",
              "      <td>82.02</td>\n",
              "      <td>2.70</td>\n",
              "      <td>9.75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.84</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1887</th>\n",
              "      <td>1888</td>\n",
              "      <td>is it possible to feel gender dysphoria but i ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-7</td>\n",
              "      <td>98</td>\n",
              "      <td>8.92</td>\n",
              "      <td>13.08</td>\n",
              "      <td>92.38</td>\n",
              "      <td>25.77</td>\n",
              "      <td>10.89</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888</th>\n",
              "      <td>1889</td>\n",
              "      <td>are there upper and lower limits for the wavel...</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>21</td>\n",
              "      <td>68.29</td>\n",
              "      <td>82.96</td>\n",
              "      <td>37.24</td>\n",
              "      <td>1.00</td>\n",
              "      <td>10.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1889</th>\n",
              "      <td>1890</td>\n",
              "      <td>very confused to start i am a 22 yr old afab n...</td>\n",
              "      <td>1</td>\n",
              "      <td>-24</td>\n",
              "      <td>299</td>\n",
              "      <td>6.83</td>\n",
              "      <td>13.49</td>\n",
              "      <td>81.69</td>\n",
              "      <td>16.24</td>\n",
              "      <td>18.69</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1890</th>\n",
              "      <td>1891</td>\n",
              "      <td>what amount of the formation of organisms is d...</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>92</td>\n",
              "      <td>65.91</td>\n",
              "      <td>74.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>45.75</td>\n",
              "      <td>30.67</td>\n",
              "      <td>...</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1891 rows × 98 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50733e33-eb41-4f85-adb3-d4639982db16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50733e33-eb41-4f85-adb3-d4639982db16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50733e33-eb41-4f85-adb3-d4639982db16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# translator = EasyNMT('opus-mt')\n",
        "\n",
        "\n",
        "# #Translate the document to German\n",
        "# print(translator.translate('Hello how are you doing?', target_lang='fr'))"
      ],
      "metadata": {
        "id": "u9Z9pANGo7Yn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translator.translate('Hello how are you doing?', target_lang='fr')"
      ],
      "metadata": {
        "id": "QgFn4tQupozI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Double translation   EN -> FR -> EN\n",
        "\n",
        "# spa_text =[]\n",
        "# new_series = []\n",
        "# for i,text in enumerate(text):\n",
        "#   print(i)\n",
        "#   if len(text) < 5000 and text is not None and text != \"\":\n",
        "#     spa_text.append(translator.translate(text, target_lang='fr'))\n",
        "#   else:\n",
        "#     spa_text.append(text)\n",
        "#     time.sleep(1)\n",
        "# for text in spa_text:\n",
        "#   print(i)\n",
        "#   if len(text) < 5000 and text is not None and text != \"\":\n",
        "#     new_series.append(translator.translate(text, target_lang='en'))\n",
        "#   else:\n",
        "#     new_series.append(text)\n",
        "#   time.sleep(1)"
      ],
      "metadata": {
        "id": "1GFpbC3-zlgC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- EXPANDING CONTRACTIONS -------------------\n",
        "\n",
        "####Uncomment the line below to use translated text\n",
        "# text = pd.read_csv('translated_text.csv')\n",
        "# text = new_series\n",
        "\n",
        "\n",
        "n_text = []\n",
        "expanded_words = []\n",
        "for i in range(len(text)):\n",
        "    a = str(text[i])\n",
        "    # -------------- LOWERCASE ----------\n",
        "    a_lower = a.lower()\n",
        "    line = a_lower.split()\n",
        "    for h in line:\n",
        "        expanded_words.append(contractions.fix(h))\n",
        "    expanded_text = ' '.join(expanded_words)\n",
        "    n_text.append(expanded_text)\n",
        "    expanded_words.clear()                  # Clearing List\n",
        "#print(n_text)\n",
        "#print('Original text: ' + text)\n",
        "#print('Expanded_text: ' + n_text)\n",
        "n_text = [str(text) for text in n_text]\n",
        "mySeries = pd.Series(n_text)\n",
        "#print(mySeries)                                                                                                                            \n",
        "# ----------------------------------------------------------"
      ],
      "metadata": {
        "id": "cCoLX-U_ecjp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = []\n",
        "w_stopwords_text = []\n",
        "for k in range(len(mySeries)):\n",
        "    a = str(mySeries[k])\n",
        "    # ----------------- REMOVING NUMBERS --------\n",
        "    text_ = ''.join([i for i in a if not i.isdigit()])\n",
        "    # -------- REMOVING SPECIAL CHARACTERS AND PUNCTUATION --------\n",
        "    punc = '''!()-[]{};:'\"\\,“”<>’./?@#$%^&*ðÿ˜=∆+_~'''\n",
        "    for j in text_:\n",
        "        if j in punc:\n",
        "            text_ = text_.replace(j,'')\n",
        "    #print(text_)\n",
        "    new_text.append(text_)\n",
        "#print(new_text)"
      ],
      "metadata": {
        "id": "v_i5S451dyPI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "DCOT-UG5xbhV",
        "outputId": "c9182d6d-909d-4fd4-88f1-5bfbfae86ea5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cyclical dysphoria cw menstruation hi there afab genderqueer enby here for the longest time i did not think i experienced dysphoria…then i realized a giant part of my increased depression and anxiety when i get my period is dysphoria i do not really know where i am going with this post but it blew my mind and i just need to word vomit about it due to my birth control i do not get a period every month but i get one often enough and i do not know how to combat the emotions i guess it is like the quintessential marker of womanhood and that is my breaking point pronouns i only care when someone is purposely being an asshole clothes i can wear anything and feel fine  of the time my chest not that big and easily streamlined if i really want to but the period i cannot do anything about it i have no choice about it it is inevitable and i am captive to its comings and goings again do not know what my point is here but if anyones read this thank you for just listening i do not have a ton of people irl to talk about these kinds of details with and i just needed to get it out'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- REMOVING STOP WORDS -------------------\n",
        "for j in range(len(new_text)):\n",
        "    text_tokens = word_tokenize(new_text[j])\n",
        "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "    filtered_sentence = (\" \").join(tokens_without_sw)\n",
        "    w_stopwords_text.append(filtered_sentence)\n",
        "#print(w_stopwords_text)\n",
        "\n",
        "col_text = pd.DataFrame(w_stopwords_text)\n",
        "final_text = col_text[0]\n",
        "#print(final_text)"
      ],
      "metadata": {
        "id": "haQK06htdvsL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------- NORMALIZING WORDS VIA LEMMATIZATION ---------------------------------\n",
        "f_sent = []\n",
        "xxx = []\n",
        "yyy = []\n",
        "for count in range(len(w_stopwords_text)):\n",
        "    b = str(w_stopwords_text[count]) \n",
        "    words_sent = b.split()\n",
        "    for j in words_sent:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        lem_sent = lemmatizer.lemmatize(j)  \n",
        "        f_sent.append(lem_sent)\n",
        "    xxx = ' '.join(f_sent)\n",
        "    yyy.append(xxx)\n",
        "    f_sent.clear()\n",
        "#print(yyy)\n",
        "\n",
        "col_text = pd.DataFrame(yyy)\n",
        "final_text = col_text[0]"
      ],
      "metadata": {
        "id": "t4afWiVsdHAn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- CLEANED DATA PLACED IN COLUMN #2 -----------\n",
        "dataset.insert(2,'new_text',final_text) \n",
        "\n",
        "#print('Clean Dataset: \\n',dataset['new_text'].values)\n",
        "print('1. Text Preprocessing Done!')\n"
      ],
      "metadata": {
        "id": "tFSJfdjPKdl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158c01dc-2619-4a9a-8f37-d999a097a06e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Text Preprocessing Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# X = dataset.drop('dysphoria',axis=1)\n",
        "X = dataset['new_text'].values\n",
        "y = dataset['dysphoria'].values\n",
        "y_labels = np.unique(y)\n",
        "\n",
        "X_train, y_train  = X,y\n",
        "#print(X_train.shape)\n",
        "#print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "SYdpF5NBCE4x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "fu0DoLQYCHf0",
        "outputId": "ba4f69bf-94e4-4f4e-e552-c33ea5d39ddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cyclical dysphoria cw menstruation hi afab genderqueer enby longest time think experienced dysphoria…then realized giant part increased depression anxiety get period dysphoria really know going post blew mind need word vomit due birth control get period every month get one often enough know combat emotion guess like quintessential marker womanhood breaking point pronoun care someone purposely asshole clothes wear anything feel fine time chest big easily streamlined really want period anything choice inevitable captive coming going know point anyones read thank listening ton people irl talk kind detail needed get',\n",
              "       'idk title pls give advice hehim trans guyi think mostly sure know friend already know one else friendlet u call v quite understand gym teacher basically said boy stand like stand stay sitting deal dysphoria godd news people class sure guy girl begin even notice told v wanted go guidance counselor talk teacher call correct pronoun thing v basically said stay u ask guy stand girl stand matter know mean transphobic thing know explain much hate considered girl',\n",
              "       'hi thereadvice please new community know reddit heh questioning gender past almost year know back easier hide could ignore like oh like crossdressing guess nothing worry breaking worse usual driving deeper depression one already sure asked people transitioned knew help much feel confused someone please give advice maybe help get panic attack dysphoria told anyone know irl scared someone help would really appreciate',\n",
              "       ..., 'upper lower limit wavelength photon highest lowest detected',\n",
              "       'confused start yr old afab nonbinary person theythem pronoun please typically come gender gender identity think much okay think confused get eventually sometimes cause breakdown recently keep getting thought head telling maybe would nonbinary amab hate fact chest often wear binder sport bra try hide fact one also always held hatred resentment towards genitals day admit okay somewhat content often find wondering would like amab instead make confused fear may confusion amongst friend family fact fact enjoy dressing feminine like wearing dress skirt feeling cute pretty know one closest friend mentioned allowed boy dress feminine still though still know would confusion hit recently since got hair cut masculine short haircut extremely happy also lately uncomfortable people addressing woman used shethey recently comfy addressed woman confusing idk go planning talking counselor',\n",
              "       'amount formation organism directly coding dna v something happening gene expressed organism ex copy gene one animal another could unknowingly change outcome gene gene x look like x used gene could use rna tell u gene gene x used would x gene shown active one produced'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[['new_text','dysphoria']]"
      ],
      "metadata": {
        "id": "kiDxjJUyDBBp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv('processed_text.csv')"
      ],
      "metadata": {
        "id": "dm7EKPIWDssX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "7H5VbnkWbo8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4d5153-60ae-4cac-e301-768cbe15153f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cyclical dysphoria cw menstruation hi afab genderqueer enby longest time think experienced dysphoria…then realized giant part increased depression anxiety get period dysphoria really know going post blew mind need word vomit due birth control get period every month get one often enough know combat emotion guess like quintessential marker womanhood breaking point pronoun care someone purposely asshole clothes wear anything feel fine time chest big easily streamlined really want period anything choice inevitable captive coming going know point anyones read thank listening ton people irl talk kind detail needed get',\n",
              "       'idk title pls give advice hehim trans guyi think mostly sure know friend already know one else friendlet u call v quite understand gym teacher basically said boy stand like stand stay sitting deal dysphoria godd news people class sure guy girl begin even notice told v wanted go guidance counselor talk teacher call correct pronoun thing v basically said stay u ask guy stand girl stand matter know mean transphobic thing know explain much hate considered girl',\n",
              "       'hi thereadvice please new community know reddit heh questioning gender past almost year know back easier hide could ignore like oh like crossdressing guess nothing worry breaking worse usual driving deeper depression one already sure asked people transitioned knew help much feel confused someone please give advice maybe help get panic attack dysphoria told anyone know irl scared someone help would really appreciate',\n",
              "       ..., 'upper lower limit wavelength photon highest lowest detected',\n",
              "       'confused start yr old afab nonbinary person theythem pronoun please typically come gender gender identity think much okay think confused get eventually sometimes cause breakdown recently keep getting thought head telling maybe would nonbinary amab hate fact chest often wear binder sport bra try hide fact one also always held hatred resentment towards genitals day admit okay somewhat content often find wondering would like amab instead make confused fear may confusion amongst friend family fact fact enjoy dressing feminine like wearing dress skirt feeling cute pretty know one closest friend mentioned allowed boy dress feminine still though still know would confusion hit recently since got hair cut masculine short haircut extremely happy also lately uncomfortable people addressing woman used shethey recently comfy addressed woman confusing idk go planning talking counselor',\n",
              "       'amount formation organism directly coding dna v something happening gene expressed organism ex copy gene one animal another could unknowingly change outcome gene gene x look like x used gene could use rna tell u gene gene x used would x gene shown active one produced'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n"
      ],
      "metadata": {
        "id": "JKo4_eDcSjf-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X, y, n_splits = 5):\n",
        "  kf = KFold(n_splits=n_splits)\n",
        "  results,train_acc,acc,precision,recall,f1,scores= [],[],[],[],[],[],[]\n",
        "  for fold, (train, test) in enumerate(kf.split(X,y)):\n",
        "    model.fit(X[train],y[train])\n",
        "    y_pred_train = model.predict(X[train])\n",
        "    y_pred = model.predict(X[test])\n",
        "    train_acc.append(accuracy_score(y[train],y_pred_train)) \n",
        "    acc.append(accuracy_score(y[test],y_pred))\n",
        "    precision.append(precision_score(y[test],y_pred)) \n",
        "    recall.append(recall_score(y[test],y_pred)) \n",
        "    f1.append(f1_score(y[test],y_pred)) \n",
        "    # print(f'Fold {fold}. Train Accuracy:{train_acc[fold]}  Test Accuracy:{acc[fold]}')\n",
        "  scores =[train_acc,acc,precision,recall,f1]\n",
        "  scores = [np.mean(score) for score in scores]\n",
        "  scores.insert(0,model.__class__.__name__)\n",
        "\n",
        "  \n",
        "  return scores\n",
        "     "
      ],
      "metadata": {
        "id": "DLA0roGfiqua"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training models"
      ],
      "metadata": {
        "id": "AS-10Ud8V6yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "#Models\n",
        "svm = SVC(kernel = 'rbf', gamma = 0.1, C = 10.0, random_state = 1)\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state = 1)\n",
        "log_reg = LogisticRegression(penalty='l2', C = 10, random_state = 1)\n",
        "ranfor = RandomForestClassifier(n_estimators=1000, max_depth=10, n_jobs=-1, ccp_alpha=0.1)\n",
        "xgbclass = xgb.XGBClassifier(n_estimators=1000,max_depth=15, learning_rate=0.05, n_jobs=-1,random_state=42,\n",
        "                                      colsample_bytree=0.5,gamma=1)\n",
        "ada = AdaBoostClassifier(n_estimators=1000,learning_rate=0.1)\n",
        "\n",
        "models =[svm,dt,log_reg,ranfor,xgbclass,ada]\n",
        "\n",
        "score_table =[]\n",
        "\n",
        "for model in models:\n",
        "  score_table.append(train(model,X_train,y_train))\n",
        "df = pd.DataFrame(score_table,columns=['Model','Train Accuracy','Test Accuracy','Precision','Recall','F1']) \n",
        "df = df.set_index('Model')\n",
        "df.sort_values('F1',ascending=False)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "HwToW4r6KgDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "b23de0f2-e9ba-40d0-a41f-a4fd6664437c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
              "Model                                                                        \n",
              "SVC                           0.997356       0.897945   0.901071  0.895568   \n",
              "LogisticRegression            0.998149       0.894769   0.903699  0.886261   \n",
              "XGBClassifier                 0.997356       0.892657   0.894083  0.892859   \n",
              "RandomForestClassifier        1.000000       0.862506   0.827711  0.917075   \n",
              "AdaBoostClassifier            0.997224       0.873093   0.896993  0.844209   \n",
              "DecisionTreeClassifier        1.000000       0.830238   0.835506  0.821387   \n",
              "\n",
              "                              F1  \n",
              "Model                             \n",
              "SVC                     0.897921  \n",
              "LogisticRegression      0.894425  \n",
              "XGBClassifier           0.893181  \n",
              "RandomForestClassifier  0.869975  \n",
              "AdaBoostClassifier      0.869510  \n",
              "DecisionTreeClassifier  0.828141  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30383bfe-1817-407a-9fc6-0f2672ceb0f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.997356</td>\n",
              "      <td>0.897945</td>\n",
              "      <td>0.901071</td>\n",
              "      <td>0.895568</td>\n",
              "      <td>0.897921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.998149</td>\n",
              "      <td>0.894769</td>\n",
              "      <td>0.903699</td>\n",
              "      <td>0.886261</td>\n",
              "      <td>0.894425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.997356</td>\n",
              "      <td>0.892657</td>\n",
              "      <td>0.894083</td>\n",
              "      <td>0.892859</td>\n",
              "      <td>0.893181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862506</td>\n",
              "      <td>0.827711</td>\n",
              "      <td>0.917075</td>\n",
              "      <td>0.869975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.997224</td>\n",
              "      <td>0.873093</td>\n",
              "      <td>0.896993</td>\n",
              "      <td>0.844209</td>\n",
              "      <td>0.869510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.830238</td>\n",
              "      <td>0.835506</td>\n",
              "      <td>0.821387</td>\n",
              "      <td>0.828141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30383bfe-1817-407a-9fc6-0f2672ceb0f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30383bfe-1817-407a-9fc6-0f2672ceb0f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30383bfe-1817-407a-9fc6-0f2672ceb0f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('F1',ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tlQsIF9a_4XH",
        "outputId": "43c9c40e-6ce5-48f2-95a2-4ea6e6b9b811"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
              "Model                                                                        \n",
              "SVC                           0.997356       0.897945   0.901071  0.895568   \n",
              "LogisticRegression            0.998149       0.894769   0.903699  0.886261   \n",
              "XGBClassifier                 0.997356       0.892657   0.894083  0.892859   \n",
              "RandomForestClassifier        1.000000       0.862506   0.827711  0.917075   \n",
              "AdaBoostClassifier            0.997224       0.873093   0.896993  0.844209   \n",
              "DecisionTreeClassifier        1.000000       0.830238   0.835506  0.821387   \n",
              "\n",
              "                              F1  \n",
              "Model                             \n",
              "SVC                     0.897921  \n",
              "LogisticRegression      0.894425  \n",
              "XGBClassifier           0.893181  \n",
              "RandomForestClassifier  0.869975  \n",
              "AdaBoostClassifier      0.869510  \n",
              "DecisionTreeClassifier  0.828141  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98b12a56-fa16-4d12-b9f1-81d23e9662a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.997356</td>\n",
              "      <td>0.897945</td>\n",
              "      <td>0.901071</td>\n",
              "      <td>0.895568</td>\n",
              "      <td>0.897921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.998149</td>\n",
              "      <td>0.894769</td>\n",
              "      <td>0.903699</td>\n",
              "      <td>0.886261</td>\n",
              "      <td>0.894425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.997356</td>\n",
              "      <td>0.892657</td>\n",
              "      <td>0.894083</td>\n",
              "      <td>0.892859</td>\n",
              "      <td>0.893181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862506</td>\n",
              "      <td>0.827711</td>\n",
              "      <td>0.917075</td>\n",
              "      <td>0.869975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.997224</td>\n",
              "      <td>0.873093</td>\n",
              "      <td>0.896993</td>\n",
              "      <td>0.844209</td>\n",
              "      <td>0.869510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.830238</td>\n",
              "      <td>0.835506</td>\n",
              "      <td>0.821387</td>\n",
              "      <td>0.828141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98b12a56-fa16-4d12-b9f1-81d23e9662a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98b12a56-fa16-4d12-b9f1-81d23e9662a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98b12a56-fa16-4d12-b9f1-81d23e9662a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks\n"
      ],
      "metadata": {
        "id": "_86nQl1SjVUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True  "
      ],
      "metadata": {
        "id": "S-7qCZi0jbpa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
      ],
      "metadata": {
        "id": "4y7fMhmKjef0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [(None, None), ('text',TEXT),('label', LABEL)]\n",
        "\n",
        "#loading custom dataset\n",
        "training_data=data.TabularDataset(path = 'processed_text.csv',format = 'csv',fields = fields,skip_header = True)\n",
        "\n",
        "#print preprocessed text\n",
        "print(vars(training_data.examples[0]))"
      ],
      "metadata": {
        "id": "yZRrv4KmjfCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1e3472-ead9-4fbc-a5f1-eabbf0c46d80"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['cyclical', 'dysphoria', 'cw', 'menstruation', 'hi', 'afab', 'genderqueer', 'enby', 'longest', 'time', 'think', 'experienced', 'dysphoria', '…', 'then', 'realized', 'giant', 'part', 'increased', 'depression', 'anxiety', 'get', 'period', 'dysphoria', 'really', 'know', 'going', 'post', 'blew', 'mind', 'need', 'word', 'vomit', 'due', 'birth', 'control', 'get', 'period', 'every', 'month', 'get', 'one', 'often', 'enough', 'know', 'combat', 'emotion', 'guess', 'like', 'quintessential', 'marker', 'womanhood', 'breaking', 'point', 'pronoun', 'care', 'someone', 'purposely', 'asshole', 'clothes', 'wear', 'anything', 'feel', 'fine', 'time', 'chest', 'big', 'easily', 'streamlined', 'really', 'want', 'period', 'anything', 'choice', 'inevitable', 'captive', 'coming', 'going', 'know', 'point', 'anyones', 'read', 'thank', 'listening', 'ton', 'people', 'irl', 'talk', 'kind', 'detail', 'needed', 'get'], 'label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(training_data.examples[0])"
      ],
      "metadata": {
        "id": "xIGRXfdPCCQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54542af9-7412-4ec7-cec3-b32e65ac3f5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '1',\n",
              " 'text': ['cyclical',\n",
              "  'dysphoria',\n",
              "  'cw',\n",
              "  'menstruation',\n",
              "  'hi',\n",
              "  'afab',\n",
              "  'genderqueer',\n",
              "  'enby',\n",
              "  'longest',\n",
              "  'time',\n",
              "  'think',\n",
              "  'experienced',\n",
              "  'dysphoria',\n",
              "  '…',\n",
              "  'then',\n",
              "  'realized',\n",
              "  'giant',\n",
              "  'part',\n",
              "  'increased',\n",
              "  'depression',\n",
              "  'anxiety',\n",
              "  'get',\n",
              "  'period',\n",
              "  'dysphoria',\n",
              "  'really',\n",
              "  'know',\n",
              "  'going',\n",
              "  'post',\n",
              "  'blew',\n",
              "  'mind',\n",
              "  'need',\n",
              "  'word',\n",
              "  'vomit',\n",
              "  'due',\n",
              "  'birth',\n",
              "  'control',\n",
              "  'get',\n",
              "  'period',\n",
              "  'every',\n",
              "  'month',\n",
              "  'get',\n",
              "  'one',\n",
              "  'often',\n",
              "  'enough',\n",
              "  'know',\n",
              "  'combat',\n",
              "  'emotion',\n",
              "  'guess',\n",
              "  'like',\n",
              "  'quintessential',\n",
              "  'marker',\n",
              "  'womanhood',\n",
              "  'breaking',\n",
              "  'point',\n",
              "  'pronoun',\n",
              "  'care',\n",
              "  'someone',\n",
              "  'purposely',\n",
              "  'asshole',\n",
              "  'clothes',\n",
              "  'wear',\n",
              "  'anything',\n",
              "  'feel',\n",
              "  'fine',\n",
              "  'time',\n",
              "  'chest',\n",
              "  'big',\n",
              "  'easily',\n",
              "  'streamlined',\n",
              "  'really',\n",
              "  'want',\n",
              "  'period',\n",
              "  'anything',\n",
              "  'choice',\n",
              "  'inevitable',\n",
              "  'captive',\n",
              "  'coming',\n",
              "  'going',\n",
              "  'know',\n",
              "  'point',\n",
              "  'anyones',\n",
              "  'read',\n",
              "  'thank',\n",
              "  'listening',\n",
              "  'ton',\n",
              "  'people',\n",
              "  'irl',\n",
              "  'talk',\n",
              "  'kind',\n",
              "  'detail',\n",
              "  'needed',\n",
              "  'get']}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
      ],
      "metadata": {
        "id": "J15LwJ7GjjAz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = \"glove.840B.300d\""
      ],
      "metadata": {
        "id": "DJwYMQh4hQDo"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize glove embeddings\n",
        "TEXT.build_vocab(train_data,min_freq=3,vectors = vocab)  \n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))  \n",
        "\n",
        "#Word dictionary\n",
        "print(TEXT.vocab.stoi)   "
      ],
      "metadata": {
        "id": "IJ43yQC0jkax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb91304-f404-463b-cac1-6f051d1a1961"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:53, 5.27MB/s]                            \n",
            "100%|█████████▉| 2196016/2196017 [03:31<00:00, 10367.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of TEXT vocabulary: 3398\n",
            "Size of LABEL vocabulary: 2\n",
            "[('like', 1939), ('feel', 1442), ('would', 1202), ('want', 1098), ('know', 998), ('gender', 932), ('dysphoria', 857), ('really', 801), ('people', 660), ('think', 659)]\n",
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7fa105ed3090>>, {'<unk>': 0, '<pad>': 1, 'like': 2, 'feel': 3, 'would': 4, 'want': 5, 'know': 6, 'gender': 7, 'dysphoria': 8, 'really': 9, 'people': 10, 'think': 11, 'get': 12, 'time': 13, 'girl': 14, 'body': 15, 'even': 16, 'woman': 17, 'thing': 18, 'one': 19, 'never': 20, 'year': 21, 'male': 22, 'feeling': 23, 'always': 24, 'make': 25, 'thought': 26, 'could': 27, 'guy': 28, 'way': 29, 'also': 30, 'female': 31, 'much': 32, 'life': 33, 'trans': 34, 'still': 35, 'look': 36, 'friend': 37, 'something': 38, 'go': 39, 'hate': 40, 'help': 41, 'see': 42, 'since': 43, 'felt': 44, 'anyone': 45, 'feminine': 46, 'lot': 47, 'man': 48, 'day': 49, 'boy': 50, 'going': 51, 'started': 52, 'say': 53, 'love': 54, 'anything': 55, 'kind': 56, 'sure': 57, 'need': 58, 'hair': 59, 'come': 60, 'men': 61, 'someone': 62, 'right': 63, 'ever': 64, 'wish': 65, 'sometimes': 66, 'back': 67, 'got': 68, 'change': 69, 'long': 70, 'find': 71, 'question': 72, 'happy': 73, 'first': 74, 'though': 75, 'told': 76, 'tell': 77, 'pretty': 78, 'sex': 79, 'made': 80, 'wear': 81, 'comfortable': 82, 'maybe': 83, 'chest': 84, 'around': 85, 'looking': 86, 'masculine': 87, 'person': 88, 'born': 89, 'idea': 90, 'wanted': 91, 'recently': 92, 'said': 93, 'good': 94, 'might': 95, 'part': 96, 'clothes': 97, 'else': 98, 'family': 99, 'pronoun': 100, 'month': 101, 'without': 102, 'school': 103, 'uncomfortable': 104, 'point': 105, 'talk': 106, 'name': 107, 'experience': 108, 'thinking': 109, 'gay': 110, 'try': 111, 'well': 112, 'little': 113, 'able': 114, 'bad': 115, 'every': 116, 'parent': 117, 'actually': 118, 'old': 119, 'please': 120, 'straight': 121, 'everything': 122, 'understand': 123, 'bit': 124, 'normal': 125, 'problem': 126, 'confused': 127, 'dress': 128, 'trying': 129, 'better': 130, 'work': 131, 'post': 132, 'getting': 133, 'identity': 134, 'take': 135, 'issue': 136, 'start': 137, 'everyone': 138, 'sorry': 139, 'advice': 140, 'keep': 141, 'mind': 142, 'used': 143, 'wrong': 144, 'fact': 145, 'many': 146, 'different': 147, 'hard': 148, 'wearing': 149, 'however': 150, 'live': 151, 'etc': 152, 'dysphoric': 153, 'mean': 154, 'scared': 155, 'last': 156, 'away': 157, 'enough': 158, 'relationship': 159, 'ago': 160, 'ci': 161, 'let': 162, 'two': 163, 'attracted': 164, 'reason': 165, 'stuff': 166, 'give': 167, 'sexual': 168, 'transition': 169, 'tried': 170, 'probably': 171, 'came': 172, 'use': 173, 'past': 174, 'nothing': 175, 'stop': 176, 'voice': 177, 'questioning': 178, 'seems': 179, 'whole': 180, 'anymore': 181, 'surgery': 182, 'weird': 183, 'guess': 184, 'either': 185, 'breast': 186, 'found': 187, 'remember': 188, 'went': 189, 'big': 190, 'new': 191, 'afab': 192, 'yet': 193, 'answer': 194, 'called': 195, 'idk': 196, 'put': 197, 'sexuality': 198, 'u': 199, 'head': 200, 'identify': 201, 'attractive': 202, 'care': 203, 'nonbinary': 204, 'short': 205, 'asked': 206, 'bi': 207, 'talking': 208, 'transgender': 209, 'completely': 210, 'call': 211, 'mom': 212, 'become': 213, 'may': 214, 'self': 215, 'sound': 216, 'wondering': 217, 'ask': 218, 'birth': 219, 'real': 220, 'week': 221, 'matter': 222, 'period': 223, 'makeup': 224, 'thanks': 225, 'today': 226, 'wanting': 227, 'end': 228, 'fucking': 229, 'least': 230, 'lesbian': 231, 'another': 232, 'best': 233, 'bisexual': 234, 'fit': 235, 'often': 236, 'hi': 237, 'seen': 238, 'worse': 239, 'anxiety': 240, 'community': 241, 'almost': 242, 'making': 243, 'saying': 244, 'constantly': 245, 'high': 246, 'penis': 247, 'place': 248, 'act': 249, 'basically': 250, 'face': 251, 'mirror': 252, 'support': 253, 'quite': 254, 'side': 255, 'age': 256, 'already': 257, 'attraction': 258, 'extremely': 259, 'le': 260, 'others': 261, 'coming': 262, 'especially': 263, 'thank': 264, 'fine': 265, 'okay': 266, 'sort': 267, 'top': 268, 'form': 269, 'kid': 270, 'term': 271, 'therapist': 272, 'deal': 273, 'possible': 274, 'realized': 275, 'word': 276, 'world': 277, 'certain': 278, 'rather': 279, 'seeing': 280, 'super': 281, 'light': 282, 'read': 283, 'transitioning': 284, 'depression': 285, 'inside': 286, 'instead': 287, 'living': 288, 'puberty': 289, 'sense': 290, 'brain': 291, 'crush': 292, 'dad': 293, 'far': 294, 'similar': 295, 'usually': 296, 'binder': 297, 'finally': 298, 'great': 299, 'mental': 300, 'child': 301, 'couple': 302, 'honestly': 303, 'online': 304, 'present': 305, 'accept': 306, 'close': 307, 'clothing': 308, 'cry': 309, 'done': 310, 'hope': 311, 'small': 312, 'whatever': 313, 'example': 314, 'hurt': 315, 'social': 316, 'using': 317, 'believe': 318, 'seem': 319, 'currently': 320, 'due': 321, 'energy': 322, 'girlfriend': 323, 'hormone': 324, 'knew': 325, 'shit': 326, 'situation': 327, 'strong': 328, 'whenever': 329, 'bra': 330, 'depressed': 331, 'imagine': 332, 'mostly': 333, 'night': 334, 'type': 335, 'binary': 336, 'young': 337, 'home': 338, 'nice': 339, 'telling': 340, 'although': 341, 'bottom': 342, 'enjoy': 343, 'hand': 344, 'hit': 345, 'lately': 346, 'liked': 347, 'looked': 348, 'story': 349, 'anyway': 350, 'girly': 351, 'later': 352, 'literally': 353, 'ok': 354, 'pain': 355, 'whether': 356, 'asking': 357, 'cut': 358, 'desire': 359, 'moment': 360, 'noticed': 361, 'sheher': 362, 'taking': 363, 'alone': 364, 'amab': 365, 'exactly': 366, 'experiencing': 367, 'figure': 368, 'hear': 369, 'reading': 370, 'sexually': 371, 'assigned': 372, 'hip': 373, 'label': 374, 'leg': 375, 'longer': 376, 'course': 377, 'fully': 378, 'group': 379, 'happen': 380, 'happened': 381, 'health': 382, 'mother': 383, 'partner': 384, 'play': 385, 'saw': 386, 'share': 387, 'boob': 388, 'fuck': 389, 'hey': 390, 'next': 391, 'physically': 392, 'porn': 393, 'towards': 394, 'upset': 395, 'absolutely': 396, 'decided': 397, 'definitely': 398, 'human': 399, 'open': 400, 'opposite': 401, 'pas': 402, 'public': 403, 'second': 404, 'true': 405, 'conversation': 406, 'huge': 407, 'physical': 408, 'therapy': 409, 'truly': 410, 'changed': 411, 'deep': 412, 'god': 413, 'number': 414, 'relate': 415, 'stand': 416, 'struggle': 417, 'androgynous': 418, 'appearance': 419, 'date': 420, 'dating': 421, 'gotten': 422, 'heard': 423, 'interested': 424, 'known': 425, 'level': 426, 'met': 427, 'starting': 428, 'confusing': 429, 'effect': 430, 'explain': 431, 'hrt': 432, 'identified': 433, 'line': 434, 'mine': 435, 'society': 436, 'space': 437, 'wave': 438, 'middle': 439, 'queer': 440, 'struggling': 441, 'supposed': 442, 'together': 443, 'worry': 444, 'amp': 445, 'appreciated': 446, 'boyfriend': 447, 'dream': 448, 'earth': 449, 'free': 450, 'fun': 451, 'knowing': 452, 'non': 453, 'simply': 454, 'vagina': 455, 'worried': 456, 'along': 457, 'case': 458, 'despite': 459, 'f': 460, 'fear': 461, 'general': 462, 'hello': 463, 'left': 464, 'lol': 465, 'loved': 466, 'realize': 467, 'show': 468, 'stupid': 469, 'water': 470, 'entire': 471, 'force': 472, 'half': 473, 'prefer': 474, 'role': 475, 'room': 476, 'sad': 477, 'skin': 478, 'state': 479, 'suddenly': 480, 'supportive': 481, 'yes': 482, 'genitals': 483, 'identifying': 484, 'mtf': 485, 'opinion': 486, 'stay': 487, 'understanding': 488, 'afraid': 489, 'amount': 490, 'became': 491, 'correct': 492, 'dick': 493, 'dressing': 494, 'ftm': 495, 'game': 496, 'genderfluid': 497, 'grow': 498, 'hated': 499, 'job': 500, 'obviously': 501, 'result': 502, 'system': 503, 'talked': 504, 'took': 505, 'turn': 506, 'video': 507, 'wife': 508, 'beautiful': 509, 'considered': 510, 'die': 511, 'doubt': 512, 'flat': 513, 'important': 514, 'interest': 515, 'needed': 516, 'outside': 517, 'testosterone': 518, 'theythem': 519, 'wishing': 520, 'younger': 521, 'accepted': 522, 'begin': 523, 'biological': 524, 'college': 525, 'cool': 526, 'current': 527, 'experienced': 528, 'femininity': 529, 'future': 530, 'growing': 531, 'hehim': 532, 'house': 533, 'joke': 534, 'masc': 535, 'move': 536, 'option': 537, 'sick': 538, 'stuck': 539, 'suck': 540, 'weight': 541, 'accepting': 542, 'asexual': 543, 'bother': 544, 'cope': 545, 'd': 546, 'dude': 547, 'easier': 548, 'except': 549, 'expect': 550, 'express': 551, 'facial': 552, 'fantasy': 553, 'gave': 554, 'gd': 555, 'gone': 556, 'happens': 557, 'hell': 558, 'hide': 559, 'i': 560, 'insurance': 561, 'mention': 562, 'must': 563, 'pressure': 564, 'related': 565, 'shirt': 566, 'sister': 567, 'stopped': 568, 'topic': 569, 'wonder': 570, 'yeah': 571, 'cause': 572, 'ended': 573, 'eventually': 574, 'eye': 575, 'hating': 576, 'notice': 577, 'playing': 578, 'sleep': 579, 'slowly': 580, 'specific': 581, 'specifically': 582, 'teen': 583, 'tired': 584, 'trigger': 585, 'turned': 586, 'ugly': 587, 'awkward': 588, 'character': 589, 'early': 590, 'feature': 591, 'full': 592, 'mum': 593, 'planet': 594, 'presenting': 595, 'somehow': 596, 'soon': 597, 'star': 598, 'watching': 599, 'area': 600, 'aware': 601, 'break': 602, 'caused': 603, 'considering': 604, 'genderqueer': 605, 'grew': 606, 'hot': 607, 'hour': 608, 'jealous': 609, 'personally': 610, 'romantic': 611, 'size': 612, 'skirt': 613, 'suicidal': 614, 'worth': 615, 'yesterday': 616, 'arm': 617, 'attention': 618, 'black': 619, 'chance': 620, 'childhood': 621, 'common': 622, 'confusion': 623, 'control': 624, 'generally': 625, 'horrible': 626, 'language': 627, 'minute': 628, 'oh': 629, 'older': 630, 'order': 631, 'referred': 632, 'rest': 633, 'set': 634, 'somewhere': 635, 'stress': 636, 'trait': 637, 'unsure': 638, 'wait': 639, 'yo': 640, 'brother': 641, 'country': 642, 'cute': 643, 'discomfort': 644, 'given': 645, 'likely': 646, 'morning': 647, 'note': 648, 'process': 649, 'reddit': 650, 'secret': 651, 'sign': 652, 'title': 653, 'adult': 654, 'affect': 655, 'avoid': 656, 'awful': 657, 'bc': 658, 'calling': 659, 'comment': 660, 'curious': 661, 'difference': 662, 'finding': 663, 'hold': 664, 'hole': 665, 'ill': 666, 'large': 667, 'leave': 668, 'personal': 669, 'rant': 670, 'reach': 671, 'ready': 672, 'strange': 673, 'sub': 674, 'teacher': 675, 'transphobic': 676, 'treated': 677, 'watch': 678, 'within': 679, 'agender': 680, 'anybody': 681, 'appreciate': 682, 'began': 683, 'behind': 684, 'changing': 685, 'class': 686, 'consider': 687, 'easy': 688, 'edit': 689, 'happier': 690, 'information': 691, 'lgbt': 692, 'masculinity': 693, 'nail': 694, 'possibility': 695, 'pregnant': 696, 'scare': 697, 'shoulder': 698, 'single': 699, 'sport': 700, 'taken': 701, 'tldr': 702, 'totally': 703, 'trip': 704, 'wore': 705, '‘': 706, 'cross': 707, 'direction': 708, 'dysmorphia': 709, 'femme': 710, 'fetish': 711, 'figured': 712, 'gross': 713, 'helped': 714, 'kept': 715, 'lose': 716, 'low': 717, 'message': 718, 'nb': 719, 'object': 720, 'phase': 721, 'picture': 722, 'preference': 723, 'response': 724, 'temperature': 725, 'universe': 726, 'actual': 727, 'attack': 728, 'badly': 729, 'broke': 730, 'choose': 731, 'confident': 732, 'discovered': 733, 'emotion': 734, 'entirely': 735, 'expression': 736, 'extreme': 737, 'fem': 738, 'fluid': 739, 'forced': 740, 'forward': 741, 'giving': 742, 'happening': 743, 'heat': 744, 'height': 745, 'helpful': 746, 'hoping': 747, 'impossible': 748, 'including': 749, 'incredibly': 750, 'lie': 751, 'meet': 752, 'mentally': 753, 'none': 754, 'obvious': 755, 'panic': 756, 'position': 757, 'reality': 758, 'science': 759, 'slightly': 760, 'somewhat': 761, 'spend': 762, 'step': 763, 'subreddit': 764, 'vent': 765, 'walk': 766, 'advance': 767, 'background': 768, 'based': 769, 'becoming': 770, 'bring': 771, 'clear': 772, 'color': 773, 'curve': 774, 'decide': 775, 'detail': 776, 'dressed': 777, 'interesting': 778, 'learned': 779, 'manly': 780, 'moved': 781, 'regret': 782, 'religious': 783, 'shave': 784, 'source': 785, 'speak': 786, 'surface': 787, 'terrible': 788, 'th': 789, 'touch': 790, 'worst': 791, 'anxious': 792, 'anyways': 793, 'buy': 794, 'cisgender': 795, 'concept': 796, 'create': 797, 'describe': 798, 'developed': 799, 'dislike': 800, 'exist': 801, 'fall': 802, 'father': 803, 'genuinely': 804, 'handle': 805, 'honest': 806, 'late': 807, 'length': 808, 'lgbtq': 809, 'possibly': 810, 'rid': 811, 'safe': 812, 'serious': 813, 'seriously': 814, 'several': 815, 'simple': 816, 'struggled': 817, 'symptom': 818, 'tip': 819, 'valid': 820, 'view': 821, 'assume': 822, 'comfort': 823, 'constant': 824, 'dealing': 825, 'denial': 826, 'disorder': 827, 'english': 828, 'everyday': 829, 'ignore': 830, 'lived': 831, 'lost': 832, 'mentioned': 833, 'misgendered': 834, 'mistake': 835, 'nearly': 836, 'necessarily': 837, 'neither': 838, 'neutral': 839, 'otherwise': 840, 'particle': 841, 'perceived': 842, 'perhaps': 843, 'personality': 844, 'pick': 845, 'plan': 846, 'reaction': 847, 'research': 848, 'run': 849, 'spectrum': 850, 'tall': 851, 'trapped': 852, 'v': 853, 'w': 854, 'carbon': 855, 'chat': 856, 'conservative': 857, 'coping': 858, 'deeper': 859, 'drug': 860, 'fairly': 861, 'genitalia': 862, 'homophobic': 863, 'hysterectomy': 864, 'image': 865, 'immediately': 866, 'intrusive': 867, 'irl': 868, 'journey': 869, 'learn': 870, 'lower': 871, 'meant': 872, 'mess': 873, 'normally': 874, 'occasionally': 875, 'pansexual': 876, 'pant': 877, 'piece': 878, 'proud': 879, 'realised': 880, 'severe': 881, 'shame': 882, 'shape': 883, 'skinny': 884, 'strongly': 885, 'trauma': 886, 'treat': 887, 'amazing': 888, 'apart': 889, 'ashamed': 890, 'baby': 891, 'baggy': 892, 'barely': 893, 'besides': 894, 'bigger': 895, 'bind': 896, 'biologically': 897, 'blood': 898, 'bought': 899, 'butt': 900, 'cycle': 901, 'deserve': 902, 'difficult': 903, 'dumb': 904, 'euphoria': 905, 'expected': 906, 'explained': 907, 'explanation': 908, 'forever': 909, 'hopefully': 910, 'internet': 911, 'kill': 912, 'main': 913, 'married': 914, 'mass': 915, 'missing': 916, 'naturally': 917, 'nervous': 918, 'nobody': 919, 'openly': 920, 'positive': 921, 'posted': 922, 'preferred': 923, 'putting': 924, 'socially': 925, 'spent': 926, 'stronger': 927, 'suicide': 928, 'three': 929, 'urge': 930, 'worked': 931, 'aspect': 932, 'assuming': 933, 'biggest': 934, 'binding': 935, 'causing': 936, 'choice': 937, 'crossdressing': 938, 'dated': 939, 'daughter': 940, 'dead': 941, 'decision': 942, 'disgusting': 943, 'doctor': 944, 'drop': 945, 'drunk': 946, 'excited': 947, 'explore': 948, 'friendship': 949, 'grade': 950, 'haircut': 951, 'handsome': 952, 'harder': 953, 'higher': 954, 'jean': 955, 'killing': 956, 'lady': 957, 'miss': 958, 'negative': 959, 'particular': 960, 'passed': 961, 'passing': 962, 'phone': 963, 'posting': 964, 'professional': 965, 'quickly': 966, 'raised': 967, 'section': 968, 'switch': 969, 'tear': 970, 'text': 971, 'treatment': 972, 'trouble': 973, 'unhappy': 974, 'university': 975, 'wall': 976, 'warning': 977, 'x': 978, 'account': 979, 'as': 980, 'beginning': 981, 'clearly': 982, 'daily': 983, 'diagnosis': 984, 'disconnected': 985, 'envy': 986, 'escape': 987, 'fast': 988, 'focus': 989, 'front': 990, 'fucked': 991, 'function': 992, 'gravity': 993, 'heart': 994, 'helping': 995, 'holding': 996, 'ideal': 997, 'lead': 998, 'losing': 999, 'medium': 1000, 'model': 1001, 'molecule': 1002, 'multiple': 1003, 'photo': 1004, 'photon': 1005, 'pm': 1006, 'private': 1007, 'refer': 1008, 'risk': 1009, 'sent': 1010, 'stick': 1011, 'subject': 1012, 'suppose': 1013, 'therefore': 1014, 'throughout': 1015, 'traditionally': 1016, 'tw': 1017, 'understood': 1018, 'unless': 1019, 'working': 1020, 'writing': 1021, 'across': 1022, 'acting': 1023, 'angry': 1024, 'atmosphere': 1025, 'bed': 1026, 'bird': 1027, 'bunch': 1028, 'connected': 1029, 'content': 1030, 'copper': 1031, 'curvy': 1032, 'diagnosed': 1033, 'distance': 1034, 'doll': 1035, 'easily': 1036, 'enby': 1037, 'event': 1038, 'expectation': 1039, 'extra': 1040, 'faking': 1041, 'field': 1042, 'fix': 1043, 'gf': 1044, 'greatly': 1045, 'ie': 1046, 'illness': 1047, 'individual': 1048, 'learning': 1049, 'list': 1050, 'mechanism': 1051, 'medical': 1052, 'member': 1053, 'orientation': 1054, 'pink': 1055, 'product': 1056, 'properly': 1057, 'psychiatrist': 1058, 'relative': 1059, 'return': 1060, 'shower': 1061, 'sit': 1062, 'smaller': 1063, 'speaking': 1064, 'standard': 1065, 'standing': 1066, 'stressed': 1067, 'style': 1068, 'suffer': 1069, 'tbh': 1070, 'teenager': 1071, 'terrified': 1072, 'till': 1073, 'tomboy': 1074, 'upon': 1075, 'wake': 1076, 'white': 1077, 'wide': 1078, 'write': 1079, '…': 1080, 'abuse': 1081, 'admit': 1082, 'afford': 1083, 'anywhere': 1084, 'appointment': 1085, 'associated': 1086, 'begun': 1087, 'belong': 1088, 'book': 1089, 'bothered': 1090, 'bullied': 1091, 'butch': 1092, 'closest': 1093, 'condition': 1094, 'confidence': 1095, 'connection': 1096, 'context': 1097, 'continue': 1098, 'crazy': 1099, 'dark': 1100, 'discussion': 1101, 'disgust': 1102, 'eat': 1103, 'eating': 1104, 'electron': 1105, 'element': 1106, 'emotional': 1107, 'enjoyed': 1108, 'fake': 1109, 'fat': 1110, 'finger': 1111, 'grown': 1112, 'guilt': 1113, 'happiness': 1114, 'he': 1115, 'hearing': 1116, 'imagining': 1117, 'impact': 1118, 'interact': 1119, 'lack': 1120, 'leaf': 1121, 'luck': 1122, 'meaning': 1123, 'memory': 1124, 'money': 1125, 'muscle': 1126, 'painful': 1127, 'pattern': 1128, 'perfect': 1129, 'power': 1130, 'pretend': 1131, 'random': 1132, 'rarely': 1133, 'reflection': 1134, 'regarding': 1135, 'rn': 1136, 'shaving': 1137, 'shopping': 1138, 'soul': 1139, 'suffering': 1140, 'summer': 1141, 'thigh': 1142, 'tho': 1143, 'thus': 1144, 'typically': 1145, 'unable': 1146, 'underwear': 1147, 'wig': 1148, 'wished': 1149, 'allowed': 1150, 'alot': 1151, 'aroused': 1152, 'article': 1153, 'atom': 1154, 'belief': 1155, 'boyish': 1156, 'brought': 1157, 'cell': 1158, 'church': 1159, 'contact': 1160, 'covid': 1161, 'data': 1162, 'distress': 1163, 'drive': 1164, 'ear': 1165, 'fight': 1166, 'floor': 1167, 'folk': 1168, 'frequency': 1169, 'gas': 1170, 'ground': 1171, 'hatred': 1172, 'hitting': 1173, 'increase': 1174, 'insight': 1175, 'kiss': 1176, 'leaving': 1177, 'led': 1178, 'liking': 1179, 'longest': 1180, 'lying': 1181, 'natural': 1182, 'numb': 1183, 'odd': 1184, 'orbit': 1185, 'organ': 1186, 'particularly': 1187, 'perceive': 1188, 'plane': 1189, 'plus': 1190, 'questioned': 1191, 'realise': 1192, 'realizing': 1193, 'rejected': 1194, 'relatively': 1195, 'romantically': 1196, 'satisfied': 1197, 'secretly': 1198, 'shot': 1199, 'solution': 1200, 'special': 1201, 'student': 1202, 'suit': 1203, 'total': 1204, 'tough': 1205, 'trust': 1206, 'truth': 1207, 'woke': 1208, 'yr': 1209, '️': 1210, 'abused': 1211, 'add': 1212, 'apologize': 1213, 'associate': 1214, 'becomes': 1215, 'benefit': 1216, 'buying': 1217, 'characteristic': 1218, 'charge': 1219, 'clean': 1220, 'closer': 1221, 'cold': 1222, 'complicated': 1223, 'concern': 1224, 'convinced': 1225, 'crisis': 1226, 'dealt': 1227, 'definition': 1228, 'develop': 1229, 'dimension': 1230, 'disgusted': 1231, 'door': 1232, 'drag': 1233, 'dropped': 1234, 'earlier': 1235, 'eg': 1236, 'embrace': 1237, 'emotionally': 1238, 'ending': 1239, 'environment': 1240, 'everywhere': 1241, 'factor': 1242, 'fair': 1243, 'fell': 1244, 'follow': 1245, 'foot': 1246, 'four': 1247, 'freak': 1248, 'gendered': 1249, 'hanging': 1250, 'harm': 1251, 'heterosexual': 1252, 'highly': 1253, 'hurting': 1254, 'husband': 1255, 'info': 1256, 'intense': 1257, 'interaction': 1258, 'internalized': 1259, 'keeping': 1260, 'kink': 1261, 'knowledge': 1262, 'larger': 1263, 'lean': 1264, 'local': 1265, 'mad': 1266, 'mainly': 1267, 'measure': 1268, 'mild': 1269, 'moon': 1270, 'moving': 1271, 'near': 1272, 'overall': 1273, 'overthinking': 1274, 'overwhelming': 1275, 'peer': 1276, 'perfectly': 1277, 'pleasure': 1278, 'quality': 1279, 'rare': 1280, 'regardless': 1281, 'relevant': 1282, 'repressed': 1283, 'rule': 1284, 'scary': 1285, 'shorter': 1286, 'speed': 1287, 'steve': 1288, 'stranger': 1289, 'study': 1290, 'sudden': 1291, 'teenage': 1292, 'tomorrow': 1293, 'toy': 1294, 'unhealthy': 1295, 'valerie': 1296, 'willing': 1297, 'acid': 1298, 'activity': 1299, 'agree': 1300, 'ahead': 1301, 'alive': 1302, 'apparently': 1303, 'appear': 1304, 'approach': 1305, 'autistic': 1306, 'ball': 1307, 'beard': 1308, 'blue': 1309, 'breaking': 1310, 'button': 1311, 'certainly': 1312, 'check': 1313, 'city': 1314, 'clue': 1315, 'conclusion': 1316, 'conscious': 1317, 'count': 1318, 'cover': 1319, 'covered': 1320, 'cuz': 1321, 'damn': 1322, 'differently': 1323, 'disappointed': 1324, 'dm': 1325, 'excuse': 1326, 'existing': 1327, 'experiment': 1328, 'fantasize': 1329, 'figuring': 1330, 'food': 1331, 'friendly': 1332, 'grandma': 1333, 'gravitational': 1334, 'hairy': 1335, 'hidden': 1336, 'insecure': 1337, 'laugh': 1338, 'listening': 1339, 'loss': 1340, 'lucky': 1341, 'mannerism': 1342, 'masturbate': 1343, 'match': 1344, 'naked': 1345, 'nowhere': 1346, 'ocean': 1347, 'offensive': 1348, 'paper': 1349, 'party': 1350, 'pill': 1351, 'pmdd': 1352, 'presentation': 1353, 'radiation': 1354, 'recent': 1355, 'reproductive': 1356, 'rough': 1357, 'running': 1358, 'scientific': 1359, 'search': 1360, 'shaved': 1361, 'shoe': 1362, 'sitting': 1363, 'sleeping': 1364, 'smile': 1365, 'soft': 1366, 'solar': 1367, 'spin': 1368, 'stomach': 1369, 'syndrome': 1370, 'test': 1371, 'theoretically': 1372, 'throw': 1373, 'tight': 1374, 'tiny': 1375, 'transitioned': 1376, 'transphobia': 1377, 'triggered': 1378, 'us': 1379, 'virus': 1380, 'weather': 1381, 'whereas': 1382, 'accident': 1383, 'active': 1384, 'actively': 1385, 'address': 1386, 'affirming': 1387, 'air': 1388, 'anatomy': 1389, 'argument': 1390, 'attempt': 1391, 'average': 1392, 'bear': 1393, 'cancer': 1394, 'claim': 1395, 'closet': 1396, 'closeted': 1397, 'co': 1398, 'complete': 1399, 'concerned': 1400, 'cried': 1401, 'crop': 1402, 'culture': 1403, 'degree': 1404, 'discover': 1405, 'elana': 1406, 'embarrassed': 1407, 'exploring': 1408, 'extent': 1409, 'falling': 1410, 'forget': 1411, 'funny': 1412, 'g': 1413, 'glad': 1414, 'google': 1415, 'guidance': 1416, 'homosexual': 1417, 'hopeless': 1418, 'incorrect': 1419, 'insecurity': 1420, 'judged': 1421, 'kissing': 1422, 'letting': 1423, 'lmao': 1424, 'managed': 1425, 'massive': 1426, 'material': 1427, 'meeting': 1428, 'mix': 1429, 'mood': 1430, 'nature': 1431, 'neck': 1432, 'nipple': 1433, 'obsession': 1434, 'ocd': 1435, 'pandemic': 1436, 'pay': 1437, 'permanent': 1438, 'played': 1439, 'prepared': 1440, 'pride': 1441, 'prion': 1442, 'proper': 1443, 'protein': 1444, 'purpose': 1445, 'push': 1446, 'quarantine': 1447, 'react': 1448, 'removed': 1449, 'sat': 1450, 'seeking': 1451, 'sensation': 1452, 'sexy': 1453, 'sibling': 1454, 'six': 1455, 'smooth': 1456, 'spoken': 1457, 'structure': 1458, 'subconsciously': 1459, 'supported': 1460, 'taller': 1461, 'technically': 1462, 'tend': 1463, 'tinder': 1464, 'toxic': 1465, 'train': 1466, 'typical': 1467, 'unfortunately': 1468, 'uterus': 1469, 'vice': 1470, 'waiting': 1471, 'welcome': 1472, 'wondered': 1473, '™': 1474, 'action': 1475, 'assumed': 1476, 'awesome': 1477, 'bathroom': 1478, 'believed': 1479, 'birthday': 1480, 'bisexuality': 1481, 'broad': 1482, 'build': 1483, 'c': 1484, 'cared': 1485, 'carry': 1486, 'cat': 1487, 'cheat': 1488, 'checking': 1489, 'christian': 1490, 'classmate': 1491, 'closed': 1492, 'compare': 1493, 'continued': 1494, 'convince': 1495, 'courage': 1496, 'cringe': 1497, 'decade': 1498, 'define': 1499, 'depending': 1500, 'depressing': 1501, 'described': 1502, 'design': 1503, 'desired': 1504, 'despise': 1505, 'discus': 1506, 'dread': 1507, 'driving': 1508, 'elementary': 1509, 'empty': 1510, 'enjoying': 1511, 'envious': 1512, 'equal': 1513, 'estrogen': 1514, 'euphoric': 1515, 'everytime': 1516, 'expressed': 1517, 'expressing': 1518, 'fellow': 1519, 'feminity': 1520, 'following': 1521, 'frame': 1522, 'frustrated': 1523, 'government': 1524, 'graduate': 1525, 'hang': 1526, 'healthy': 1527, 'heavily': 1528, 'horny': 1529, 'ignored': 1530, 'impression': 1531, 'informed': 1532, 'input': 1533, 'ish': 1534, 'k': 1535, 'kissed': 1536, 'leading': 1537, 'legal': 1538, 'major': 1539, 'masturbation': 1540, 'method': 1541, 'mid': 1542, 'minor': 1543, 'misogyny': 1544, 'motivation': 1545, 'movie': 1546, 'muscular': 1547, 'neutron': 1548, 'noise': 1549, 'noticeable': 1550, 'p': 1551, 'pair': 1552, 'per': 1553, 'physic': 1554, 'picked': 1555, 'planning': 1556, 'pls': 1557, 'polish': 1558, 'ppl': 1559, 'pregnancy': 1560, 'press': 1561, 'primary': 1562, 'produce': 1563, 'prove': 1564, 'pull': 1565, 'rambling': 1566, 'reached': 1567, 'record': 1568, 'referring': 1569, 'regularly': 1570, 'relating': 1571, 'relief': 1572, 'religion': 1573, 'remind': 1574, 'resource': 1575, 'ridiculous': 1576, 'rocket': 1577, 'scenario': 1578, 'searching': 1579, 'secondary': 1580, 'seek': 1581, 'sensory': 1582, 'session': 1583, 'shift': 1584, 'shitty': 1585, 'sight': 1586, 'sir': 1587, 'somebody': 1588, 'song': 1589, 'square': 1590, 'statement': 1591, 'store': 1592, 'subtle': 1593, 'suggestion': 1594, 'teach': 1595, 'technology': 1596, 'theory': 1597, 'thick': 1598, 'thread': 1599, 'touched': 1600, 'traditional': 1601, 'transfer': 1602, 'travel': 1603, 'tv': 1604, 'twice': 1605, 'ugh': 1606, 'unknown': 1607, 'vehicle': 1608, 'versa': 1609, 'via': 1610, 'vibe': 1611, 'virtual': 1612, 'visible': 1613, 'waited': 1614, 'weak': 1615, 'abnormal': 1616, 'acceptance': 1617, 'access': 1618, 'accurate': 1619, 'ace': 1620, 'affected': 1621, 'andor': 1622, 'asks': 1623, 'attached': 1624, 'b': 1625, 'balance': 1626, 'battery': 1627, 'beat': 1628, 'behavior': 1629, 'bf': 1630, 'bigender': 1631, 'biromantic': 1632, 'blocker': 1633, 'breakdown': 1634, 'btw': 1635, 'bullying': 1636, 'calm': 1637, 'capable': 1638, 'card': 1639, 'category': 1640, 'caught': 1641, 'celebrity': 1642, 'chemistry': 1643, 'chubby': 1644, 'circle': 1645, 'collision': 1646, 'compound': 1647, 'conflicted': 1648, 'connect': 1649, 'core': 1650, 'coworkers': 1651, 'created': 1652, 'crime': 1653, 'crippling': 1654, 'death': 1655, 'dense': 1656, 'deny': 1657, 'development': 1658, 'disconnection': 1659, 'discussed': 1660, 'disease': 1661, 'drink': 1662, 'effort': 1663, 'egg': 1664, 'episode': 1665, 'erection': 1666, 'esteem': 1667, 'everybody': 1668, 'evidence': 1669, 'ex': 1670, 'exact': 1671, 'exhausting': 1672, 'fan': 1673, 'fashion': 1674, 'fault': 1675, 'fighting': 1676, 'final': 1677, 'five': 1678, 'football': 1679, 'foreign': 1680, 'forum': 1681, 'freedom': 1682, 'frustrating': 1683, 'grid': 1684, 'hairline': 1685, 'happily': 1686, 'heavy': 1687, 'heel': 1688, 'hiding': 1689, 'history': 1690, 'hormonal': 1691, 'hug': 1692, 'ignoring': 1693, 'ik': 1694, 'included': 1695, 'independent': 1696, 'infinite': 1697, 'initiate': 1698, 'insane': 1699, 'intention': 1700, 'interacting': 1701, 'iron': 1702, 'jaw': 1703, 'join': 1704, 'laughed': 1705, 'launch': 1706, 'law': 1707, 'lip': 1708, 'loud': 1709, 'luckily': 1710, 'manage': 1711, 'manner': 1712, 'mate': 1713, 'medication': 1714, 'messed': 1715, 'million': 1716, 'movement': 1717, 'muslim': 1718, 'nerve': 1719, 'nonconforming': 1720, 'noticing': 1721, 'nub': 1722, 'onto': 1723, 'orgasm': 1724, 'outright': 1725, 'oxygen': 1726, 'pan': 1727, 'partial': 1728, 'path': 1729, 'patina': 1730, 'peace': 1731, 'permanently': 1732, 'perspective': 1733, 'platonic': 1734, 'potential': 1735, 'pretending': 1736, 'previously': 1737, 'property': 1738, 'proton': 1739, 'pushed': 1740, 'ran': 1741, 'range': 1742, 'ranting': 1743, 'rd': 1744, 'recommendation': 1745, 'reduction': 1746, 'reference': 1747, 'refers': 1748, 'refused': 1749, 'regular': 1750, 'reminds': 1751, 'repress': 1752, 'respect': 1753, 'ride': 1754, 'salt': 1755, 'satisfy': 1756, 'sea': 1757, 'seemed': 1758, 'send': 1759, 'shadow': 1760, 'shaped': 1761, 'showing': 1762, 'silent': 1763, 'skill': 1764, 'solid': 1765, 'sounding': 1766, 'specie': 1767, 'stable': 1768, 'stare': 1769, 'staring': 1770, 'stereotypical': 1771, 'strength': 1772, 'subreddits': 1773, 'taste': 1774, 'taught': 1775, 'terrifying': 1776, 'thin': 1777, 'third': 1778, 'tights': 1779, 'tiktok': 1780, 'tunnel': 1781, 'typing': 1782, 'uni': 1783, 'unique': 1784, 'usual': 1785, 'various': 1786, 'walked': 1787, 'walking': 1788, 'watched': 1789, 'winter': 1790, 'worn': 1791, 'zero': 1792, '\\u200d': 1793, '„': 1794, '🤷': 1795, '`': 1796, 'acceptable': 1797, 'acted': 1798, 'added': 1799, 'adhd': 1800, 'aesthetic': 1801, 'alcohol': 1802, 'allow': 1803, 'alpha': 1804, 'american': 1805, 'anal': 1806, 'animal': 1807, 'annoyed': 1808, 'anytime': 1809, 'apple': 1810, 'apply': 1811, 'asab': 1812, 'aside': 1813, 'asshole': 1814, 'attacked': 1815, 'attitude': 1816, 'awhile': 1817, 'bag': 1818, 'bet': 1819, 'bleeding': 1820, 'board': 1821, 'boiling': 1822, 'bolt': 1823, 'bone': 1824, 'boring': 1825, 'box': 1826, 'brings': 1827, 'broken': 1828, 'burst': 1829, 'car': 1830, 'chosen': 1831, 'closely': 1832, 'cloud': 1833, 'club': 1834, 'company': 1835, 'complex': 1836, 'compliment': 1837, 'conflict': 1838, 'continues': 1839, 'copy': 1840, 'corner': 1841, 'correctly': 1842, 'counselor': 1843, 'criterion': 1844, 'cup': 1845, 'damage': 1846, 'deeply': 1847, 'defined': 1848, 'delete': 1849, 'demon': 1850, 'density': 1851, 'description': 1852, 'desperate': 1853, 'destroy': 1854, 'died': 1855, 'disclaimer': 1856, 'discovery': 1857, 'draw': 1858, 'dye': 1859, 'dying': 1860, 'e': 1861, 'edge': 1862, 'electrical': 1863, 'embracing': 1864, 'emitted': 1865, 'encounter': 1866, 'equilibrium': 1867, 'existence': 1868, 'exists': 1869, 'experimenting': 1870, 'exposed': 1871, 'familiar': 1872, 'faster': 1873, 'feasible': 1874, 'femboy': 1875, 'forgot': 1876, 'fusion': 1877, 'gain': 1878, 'galaxy': 1879, 'gene': 1880, 'giant': 1881, 'goal': 1882, 'grasp': 1883, 'graygender': 1884, 'greater': 1885, 'guilty': 1886, 'gut': 1887, 'haha': 1888, 'hardly': 1889, 'heck': 1890, 'highschool': 1891, 'hobby': 1892, 'homosexuality': 1893, 'hoodie': 1894, 'hoodies': 1895, 'horribly': 1896, 'household': 1897, 'hysto': 1898, 'identifies': 1899, 'imposter': 1900, 'increasingly': 1901, 'insult': 1902, 'intensity': 1903, 'interference': 1904, 'involved': 1905, 'judge': 1906, 'jump': 1907, 'letter': 1908, 'link': 1909, 'listen': 1910, 'loose': 1911, 'loving': 1912, 'machine': 1913, 'march': 1914, 'marry': 1915, 'mile': 1916, 'minded': 1917, 'minimal': 1918, 'minimum': 1919, 'minority': 1920, 'moreso': 1921, 'necessary': 1922, 'offense': 1923, 'officially': 1924, 'orbital': 1925, 'original': 1926, 'outcome': 1927, 'overcome': 1928, 'overweight': 1929, 'panicking': 1930, 'paragraph': 1931, 'partially': 1932, 'patient': 1933, 'perception': 1934, 'pipe': 1935, 'pitch': 1936, 'placed': 1937, 'pop': 1938, 'powerful': 1939, 'privilege': 1940, 'proof': 1941, 'protect': 1942, 'provide': 1943, 'psychologist': 1944, 'punishment': 1945, 'quick': 1946, 'rape': 1947, 'realisation': 1948, 'recognize': 1949, 'regard': 1950, 'reminded': 1951, 'reply': 1952, 'required': 1953, 'respond': 1954, 'romance': 1955, 'rude': 1956, 'scale': 1957, 'scientist': 1958, 'seed': 1959, 'sensitive': 1960, 'setting': 1961, 'severely': 1962, 'sharing': 1963, 'shethey': 1964, 'ship': 1965, 'shocked': 1966, 'shy': 1967, 'signal': 1968, 'silicon': 1969, 'son': 1970, 'south': 1971, 'speaker': 1972, 'st': 1973, 'stopping': 1974, 'substance': 1975, 'surely': 1976, 'target': 1977, 'tea': 1978, 'town': 1979, 'unbearable': 1980, 'update': 1981, 'vague': 1982, 'waist': 1983, 'waking': 1984, 'wavelength': 1985, 'wednesday': 1986, 'weekend': 1987, 'whatsoever': 1988, 'worthless': 1989, 'wrote': 1990, 'youtube': 1991, 'ab': 1992, 'absolute': 1993, 'according': 1994, 'acknowledge': 1995, 'activated': 1996, 'additional': 1997, 'admire': 1998, 'agab': 1999, 'agp': 2000, 'alleviate': 2001, 'alter': 2002, 'anguish': 2003, 'anime': 2004, 'annoying': 2005, 'apartment': 2006, 'apologise': 2007, 'applied': 2008, 'apps': 2009, 'april': 2010, 'arousal': 2011, 'aunty': 2012, 'autism': 2013, 'automatically': 2014, 'basis': 2015, 'battle': 2016, 'beam': 2017, 'beyond': 2018, 'bond': 2019, 'bored': 2020, 'bothering': 2021, 'bottle': 2022, 'breakup': 2023, 'bro': 2024, 'brush': 2025, 'bullshit': 2026, 'caring': 2027, 'center': 2028, 'certificate': 2029, 'chemical': 2030, 'chinese': 2031, 'clarify': 2032, 'clicked': 2033, 'clinical': 2034, 'colour': 2035, 'combination': 2036, 'communicate': 2037, 'comphet': 2038, 'concluded': 2039, 'confuse': 2040, 'confuses': 2041, 'consent': 2042, 'cop': 2043, 'cost': 2044, 'cousin': 2045, 'creating': 2046, 'cuddling': 2047, 'cw': 2048, 'dangerous': 2049, 'daydream': 2050, 'daydreaming': 2051, 'decay': 2052, 'december': 2053, 'decent': 2054, 'demigirl': 2055, 'denied': 2056, 'depressive': 2057, 'desperately': 2058, 'developing': 2059, 'directly': 2060, 'dissociation': 2061, 'distressed': 2062, 'dose': 2063, 'drama': 2064, 'drawing': 2065, 'dreamed': 2066, 'dreaming': 2067, 'drinking': 2068, 'dry': 2069, 'ed': 2070, 'effeminate': 2071, 'electricity': 2072, 'equivalent': 2073, 'evening': 2074, 'exciting': 2075, 'exclusively': 2076, 'explaining': 2077, 'extended': 2078, 'eyeliner': 2079, 'fancy': 2080, 'february': 2081, 'femenine': 2082, 'fictional': 2083, 'fill': 2084, 'filled': 2085, 'finish': 2086, 'fire': 2087, 'flip': 2088, 'flirt': 2089, 'focused': 2090, 'formed': 2091, 'freaking': 2092, 'frustration': 2093, 'gamma': 2094, 'genderneutral': 2095, 'gentle': 2096, 'glucose': 2097, 'grateful': 2098, 'grip': 2099, 'growth': 2100, 'habit': 2101, 'halloween': 2102, 'hangout': 2103, 'hardest': 2104, 'held': 2105, 'homeless': 2106, 'huh': 2107, 'hung': 2108, 'hz': 2109, 'include': 2110, 'incomplete': 2111, 'increasing': 2112, 'indifferent': 2113, 'influence': 2114, 'inherently': 2115, 'instantly': 2116, 'internal': 2117, 'intimate': 2118, 'invalidate': 2119, 'invalidated': 2120, 'item': 2121, 'jealousy': 2122, 'journal': 2123, 'judgement': 2124, 'junior': 2125, 'km': 2126, 'labeled': 2127, 'land': 2128, 'laser': 2129, 'legit': 2130, 'lied': 2131, 'limit': 2132, 'lipstick': 2133, 'lowest': 2134, 'lsd': 2135, 'manifest': 2136, 'masturbating': 2137, 'mechanic': 2138, 'menstruation': 2139, 'mildly': 2140, 'misgender': 2141, 'mistaken': 2142, 'mobile': 2143, 'mosquito': 2144, 'mouth': 2145, 'national': 2146, 'nightmare': 2147, 'nine': 2148, 'norm': 2149, 'novel': 2150, 'numerous': 2151, 'nurse': 2152, 'nutrient': 2153, 'observed': 2154, 'observer': 2155, 'occurred': 2156, 'october': 2157, 'offer': 2158, 'oneself': 2159, 'orbitals': 2160, 'originally': 2161, 'overly': 2162, 'page': 2163, 'paint': 2164, 'paradox': 2165, 'paranoid': 2166, 'park': 2167, 'pcos': 2168, 'persistent': 2169, 'pin': 2170, 'piss': 2171, 'plant': 2172, 'pornography': 2173, 'potentially': 2174, 'prison': 2175, 'pro': 2176, 'profile': 2177, 'psychological': 2178, 'pulling': 2179, 'purely': 2180, 'purposely': 2181, 'pursue': 2182, 'pursuing': 2183, 'queen': 2184, 'r': 2185, 'race': 2186, 'radioactive': 2187, 'ramble': 2188, 'raskscience': 2189, 'ray': 2190, 'red': 2191, 'refuse': 2192, 'relation': 2193, 'release': 2194, 'relieved': 2195, 'remain': 2196, 'remembered': 2197, 'reminder': 2198, 'repression': 2199, 'repulsed': 2200, 'repulsive': 2201, 'resentment': 2202, 'respectively': 2203, 'reverse': 2204, 'rise': 2205, 'root': 2206, 'round': 2207, 'sake': 2208, 'scream': 2209, 'seemingly': 2210, 'sender': 2211, 'separate': 2212, 'series': 2213, 'sharp': 2214, 'silly': 2215, 'skip': 2216, 'sky': 2217, 'slight': 2218, 'slow': 2219, 'slur': 2220, 'sooner': 2221, 'spending': 2222, 'spinning': 2223, 'spot': 2224, 'spread': 2225, 'stage': 2226, 'station': 2227, 'staying': 2228, 'stereotype': 2229, 'stone': 2230, 'strain': 2231, 'string': 2232, 'success': 2233, 'suffered': 2234, 'suggested': 2235, 'suitable': 2236, 'sum': 2237, 'surrounded': 2238, 'swear': 2239, 'tech': 2240, 'tendency': 2241, 'tf': 2242, 'thankfully': 2243, 'threw': 2244, 'tissue': 2245, 'tit': 2246, 'ton': 2247, 'tonight': 2248, 'track': 2249, 'training': 2250, 'transferred': 2251, 'transsexual': 2252, 'truck': 2253, 'twin': 2254, 'unattractive': 2255, 'unlikely': 2256, 'unnatural': 2257, 'unrelated': 2258, 'useful': 2259, 'value': 2260, 'variable': 2261, 'venting': 2262, 'vessel': 2263, 'virgin': 2264, 'weaker': 2265, 'website': 2266, 'whatnot': 2267, 'whilst': 2268, 'whisper': 2269, 'wise': 2270, 'womanhood': 2271, 'wow': 2272, 'yea': 2273, 'yearold': 2274, 'yknow': 2275, '»': 2276, '♂': 2277, '😅': 2278, '😭': 2279, 'ability': 2280, 'abt': 2281, 'abusive': 2282, 'accidentally': 2283, 'achieve': 2284, 'acquaintance': 2285, 'addressed': 2286, 'admitting': 2287, 'affecting': 2288, 'agreed': 2289, 'aid': 2290, 'align': 2291, 'allowing': 2292, 'ally': 2293, 'alright': 2294, 'amino': 2295, 'analogy': 2296, 'analyze': 2297, 'answered': 2298, 'answering': 2299, 'anti': 2300, 'apathetic': 2301, 'appealing': 2302, 'appears': 2303, 'artificial': 2304, 'asian': 2305, 'assaulted': 2306, 'assign': 2307, 'association': 2308, 'assumes': 2309, 'atm': 2310, 'atmospheric': 2311, 'attempted': 2312, 'aunt': 2313, 'awake': 2314, 'backstory': 2315, 'backwards': 2316, 'bang': 2317, 'bare': 2318, 'barrier': 2319, 'basic': 2320, 'beale': 2321, 'beaten': 2322, 'behaviour': 2323, 'believing': 2324, 'bias': 2325, 'biology': 2326, 'bitch': 2327, 'boil': 2328, 'bomb': 2329, 'boom': 2330, 'boot': 2331, 'breath': 2332, 'breathe': 2333, 'breathing': 2334, 'bringing': 2335, 'building': 2336, 'burning': 2337, 'busy': 2338, 'calculation': 2339, 'cannon': 2340, 'chain': 2341, 'charged': 2342, 'cheating': 2343, 'cheer': 2344, 'christianity': 2345, 'chromosome': 2346, 'circumstance': 2347, 'clarity': 2348, 'commit': 2349, 'committed': 2350, 'communication': 2351, 'comparison': 2352, 'computer': 2353, 'concentration': 2354, 'conflicting': 2355, 'conforming': 2356, 'construct': 2357, 'continuous': 2358, 'conventionally': 2359, 'convey': 2360, 'corrected': 2361, 'coworker': 2362, 'crap': 2363, 'creep': 2364, 'criticism': 2365, 'crossdress': 2366, 'crossdresser': 2367, 'crossed': 2368, 'curiosity': 2369, 'curly': 2370, 'dance': 2371, 'describes': 2372, 'describing': 2373, 'detailed': 2374, 'difficulty': 2375, 'dinner': 2376, 'disassociate': 2377, 'discovering': 2378, 'disliked': 2379, 'dissociated': 2380, 'distant': 2381, 'distinct': 2382, 'distraction': 2383, 'document': 2384, 'dolphin': 2385, 'dominate': 2386, 'dominating': 2387, 'dramatic': 2388, 'drawn': 2389, 'earliest': 2390, 'earthquake': 2391, 'ease': 2392, 'ect': 2393, 'el': 2394, 'emailed': 2395, 'embarrassing': 2396, 'embarrassment': 2397, 'employee': 2398, 'energetic': 2399, 'energymatter': 2400, 'engage': 2401, 'engineer': 2402, 'engineering': 2403, 'enjoyment': 2404, 'entropy': 2405, 'equally': 2406, 'error': 2407, 'essentially': 2408, 'existed': 2409, 'experimented': 2410, 'expert': 2411, 'extension': 2412, 'extensively': 2413, 'eyebrow': 2414, 'faced': 2415, 'facing': 2416, 'fade': 2417, 'failed': 2418, 'fantasizing': 2419, 'fascination': 2420, 'favor': 2421, 'favorite': 2422, 'feedback': 2423, 'feeder': 2424, 'femine': 2425, 'film': 2426, 'filter': 2427, 'flatter': 2428, 'flaw': 2429, 'flow': 2430, 'fluffy': 2431, 'fluidity': 2432, 'focusing': 2433, 'forcing': 2434, 'former': 2435, 'forming': 2436, 'fraction': 2437, 'frequently': 2438, 'frozen': 2439, 'ft': 2440, 'fulfilling': 2441, 'gained': 2442, 'genderless': 2443, 'generate': 2444, 'genetic': 2445, 'genuine': 2446, 'googling': 2447, 'grammar': 2448, 'grandmother': 2449, 'granted': 2450, 'grey': 2451, 'h': 2452, 'hat': 2453, 'healthcare': 2454, 'heated': 2455, 'heaven': 2456, 'heterosexuality': 2457, 'himher': 2458, 'holiday': 2459, 'homo': 2460, 'homophobia': 2461, 'hoped': 2462, 'hopeful': 2463, 'hospital': 2464, 'host': 2465, 'hugging': 2466, 'hurtful': 2467, 'ignorant': 2468, 'ii': 2469, 'imaging': 2470, 'imbalance': 2471, 'imitate': 2472, 'immensely': 2473, 'implies': 2474, 'importance': 2475, 'importantly': 2476, 'incident': 2477, 'inclusive': 2478, 'inherent': 2479, 'initial': 2480, 'initially': 2481, 'inner': 2482, 'insert': 2483, 'intend': 2484, 'interpretation': 2485, 'intersex': 2486, 'introspection': 2487, 'intuitive': 2488, 'invited': 2489, 'japanese': 2490, 'jewelry': 2491, 'joining': 2492, 'june': 2493, 'lab': 2494, 'lasted': 2495, 'laughing': 2496, 'lb': 2497, 'leaning': 2498, 'legend': 2499, 'legging': 2500, 'lgbtqia': 2501, 'liberal': 2502, 'libido': 2503, 'lifestyle': 2504, 'lift': 2505, 'likewise': 2506, 'load': 2507, 'lockdown': 2508, 'loses': 2509, 'lovely': 2510, 'lump': 2511, 'maintain': 2512, 'majority': 2513, 'marriage': 2514, 'marrying': 2515, 'math': 2516, 'mathematical': 2517, 'meaningful': 2518, 'meanwhile': 2519, 'meat': 2520, 'med': 2521, 'medically': 2522, 'medicine': 2523, 'meme': 2524, 'merely': 2525, 'messy': 2526, 'metal': 2527, 'meteorite': 2528, 'meter': 2529, 'mindset': 2530, 'minivan': 2531, 'miserable': 2532, 'misgendering': 2533, 'music': 2534, 'neat': 2535, 'net': 2536, 'nsfw': 2537, 'obsessed': 2538, 'obstacle': 2539, 'occasion': 2540, 'occasional': 2541, 'offended': 2542, 'opened': 2543, 'opening': 2544, 'opportunity': 2545, 'orbiting': 2546, 'origin': 2547, 'overwhelmed': 2548, 'paid': 2549, 'painting': 2550, 'partly': 2551, 'passage': 2552, 'penetrate': 2553, 'perceiving': 2554, 'petite': 2555, 'pity': 2556, 'planck': 2557, 'plasma': 2558, 'plastic': 2559, 'pluto': 2560, 'poc': 2561, 'pocket': 2562, 'pointed': 2563, 'police': 2564, 'pool': 2565, 'popular': 2566, 'pound': 2567, 'pray': 2568, 'pre': 2569, 'pressing': 2570, 'princess': 2571, 'probability': 2572, 'procedure': 2573, 'proceed': 2574, 'progress': 2575, 'project': 2576, 'prominent': 2577, 'pub': 2578, 'purge': 2579, 'purity': 2580, 'puzzle': 2581, 'quiz': 2582, 'racism': 2583, 'radio': 2584, 'radius': 2585, 'rain': 2586, 'randomly': 2587, 'raped': 2588, 'reassurance': 2589, 'recurring': 2590, 'rejection': 2591, 'relates': 2592, 'reminding': 2593, 'remove': 2594, 'replacing': 2595, 'report': 2596, 'respected': 2597, 'restriction': 2598, 'rollercoaster': 2599, 'roommate': 2600, 'rotation': 2601, 'safely': 2602, 'safer': 2603, 'satan': 2604, 'satisfying': 2605, 'save': 2606, 'screen': 2607, 'se': 2608, 'secondly': 2609, 'selfconscious': 2610, 'selfhate': 2611, 'selfish': 2612, 'service': 2613, 'sexualized': 2614, 'shaky': 2615, 'shut': 2616, 'significant': 2617, 'similarity': 2618, 'simulation': 2619, 'singing': 2620, 'sm': 2621, 'smart': 2622, 'snap': 2623, 'snow': 2624, 'societal': 2625, 'sock': 2626, 'someday': 2627, 'soulmate': 2628, 'sounded': 2629, 'spare': 2630, 'spiral': 2631, 'spirit': 2632, 'spoke': 2633, 'spoon': 2634, 'stared': 2635, 'stated': 2636, 'stereotypically': 2637, 'stigma': 2638, 'stolen': 2639, 'street': 2640, 'stressful': 2641, 'stressing': 2642, 'strict': 2643, 'studying': 2644, 'submissive': 2645, 'successful': 2646, 'suited': 2647, 'superficial': 2648, 'supporter': 2649, 'suppress': 2650, 'suppressed': 2651, 'surprise': 2652, 'suspect': 2653, 'sweater': 2654, 'sympathetic': 2655, 'table': 2656, 'tampon': 2657, 'temporary': 2658, 'ten': 2659, 'tense': 2660, 'terfs': 2661, 'textbook': 2662, 'theme': 2663, 'theoretical': 2664, 'throwing': 2665, 'tied': 2666, 'tool': 2667, 'toward': 2668, 'transform': 2669, 'transformation': 2670, 'transwoman': 2671, 'tshirt': 2672, 'tshirts': 2673, 'tucking': 2674, 'turning': 2675, 'twitter': 2676, 'typed': 2677, 'uncle': 2678, 'unfortunate': 2679, 'uniform': 2680, 'unwanted': 2681, 'user': 2682, 'utterly': 2683, 'validate': 2684, 'validation': 2685, 'variety': 2686, 'velocity': 2687, 'viable': 2688, 'visual': 2689, 'vivid': 2690, 'war': 2691, 'warm': 2692, 'weighing': 2693, 'welcomed': 2694, 'wider': 2695, 'window': 2696, 'wlw': 2697, 'wood': 2698, 'worthy': 2699, 'yelled': 2700, 'youth': 2701, 'z': 2702, '¿': 2703, 'â': 2704, '–': 2705, 'absorb': 2706, 'absorbed': 2707, 'absorbs': 2708, 'absorption': 2709, 'abusing': 2710, 'accepts': 2711, 'accessory': 2712, 'accurately': 2713, 'ache': 2714, 'ad': 2715, 'adam': 2716, 'adding': 2717, 'additionally': 2718, 'admitted': 2719, 'adopt': 2720, 'advise': 2721, 'africa': 2722, 'aka': 2723, 'alongside': 2724, 'altered': 2725, 'alternative': 2726, 'altitude': 2727, 'altogether': 2728, 'ama': 2729, 'ambiguous': 2730, 'among': 2731, 'androgynously': 2732, 'anger': 2733, 'angle': 2734, 'angular': 2735, 'antidepressant': 2736, 'anyones': 2737, 'apology': 2738, 'appeal': 2739, 'applying': 2740, 'appropriate': 2741, 'approve': 2742, 'armor': 2743, 'army': 2744, 'arrives': 2745, 'art': 2746, 'asleep': 2747, 'aspergers': 2748, 'assault': 2749, 'assumption': 2750, 'aswell': 2751, 'atleast': 2752, 'atomic': 2753, 'attribute': 2754, 'august': 2755, 'authentic': 2756, 'autogynephilia': 2757, 'avoiding': 2758, 'ax': 2759, 'axis': 2760, 'bald': 2761, 'banana': 2762, 'bar': 2763, 'base': 2764, 'basement': 2765, 'beak': 2766, 'beating': 2767, 'behave': 2768, 'bell': 2769, 'belongs': 2770, 'beta': 2771, 'bible': 2772, 'bill': 2773, 'billion': 2774, 'bio': 2775, 'blah': 2776, 'block': 2777, 'bloke': 2778, 'blond': 2779, 'blowjob': 2780, 'boat': 2781, 'bottled': 2782, 'boundary': 2783, 'bout': 2784, 'boxer': 2785, 'breakthrough': 2786, 'breastfeeding': 2787, 'bugged': 2788, 'built': 2789, 'bum': 2790, 'business': 2791, 'buzz': 2792, 'calmed': 2793, 'camp': 2794, 'career': 2795, 'carried': 2796, 'catch': 2797, 'catching': 2798, 'celestial': 2799, 'challenge': 2800, 'channel': 2801, 'cherry': 2802, 'chicken': 2803, 'chop': 2804, 'chronic': 2805, 'cishet': 2806, 'cl': 2807, 'classified': 2808, 'cleaned': 2809, 'cleared': 2810, 'clockwise': 2811, 'clout': 2812, 'code': 2813, 'coil': 2814, 'collapse': 2815, 'collection': 2816, 'collector': 2817, 'colored': 2818, 'combat': 2819, 'comfortably': 2820, 'comforting': 2821, 'comfy': 2822, 'communicating': 2823, 'complication': 2824, 'complimented': 2825, 'component': 2826, 'comprehend': 2827, 'con': 2828, 'concise': 2829, 'confide': 2830, 'confirm': 2831, 'consciously': 2832, 'consequence': 2833, 'consistent': 2834, 'consistently': 2835, 'contentment': 2836, 'contraction': 2837, 'contribute': 2838, 'controlling': 2839, 'convert': 2840, 'cooking': 2841, 'cooler': 2842, 'correcting': 2843, 'couch': 2844, 'court': 2845, 'coz': 2846, 'crackling': 2847, 'cramp': 2848, 'creation': 2849, 'creative': 2850, 'creeping': 2851, 'crystal': 2852, 'cure': 2853, 'cured': 2854, 'curie': 2855, 'cutting': 2856, 'dampd': 2857, 'darkness': 2858, 'deadname': 2859, 'deadnamed': 2860, 'dear': 2861, 'debilitating': 2862, 'deepen': 2863, 'delaware': 2864, 'delayed': 2865, 'dependence': 2866, 'dependent': 2867, 'destroyed': 2868, 'destructive': 2869, 'determine': 2870, 'determined': 2871, 'device': 2872, 'devil': 2873, 'diagnostic': 2874, 'disappear': 2875, 'disappeared': 2876, 'discrimination': 2877, 'discussing': 2878, 'disphoria': 2879, 'distracted': 2880, 'distribution': 2881, 'dosage': 2882, 'double': 2883, 'dr': 2884, 'drastic': 2885, 'dropping': 2886, 'drowning': 2887, 'dyed': 2888, 'dynamic': 2889, 'dysohoria': 2890, 'eachother': 2891, 'eastern': 2892, 'education': 2893, 'eggirl': 2894, 'eight': 2895, 'elective': 2896, 'electromagnet': 2897, 'electromagnetic': 2898, 'emit': 2899, 'emphasis': 2900, 'engaged': 2901, 'enter': 2902, 'entity': 2903, 'est': 2904, 'evolution': 2905, 'exaggerated': 2906, 'exception': 2907, 'excites': 2908, 'excluded': 2909, 'exercise': 2910, 'exhausted': 2911, 'exhaustion': 2912, 'existential': 2913, 'expand': 2914, 'expansion': 2915, 'expecting': 2916, 'expense': 2917, 'explicitly': 2918, 'extend': 2919, 'extract': 2920, 'fabulous': 2921, 'facebook': 2922, 'famous': 2923, 'fantasising': 2924, 'fantasized': 2925, 'fearing': 2926, 'fed': 2927, 'felling': 2928, 'femaleness': 2929, 'femininely': 2930, 'feminising': 2931, 'femmepresenting': 2932, 'femmes': 2933, 'fiance': 2934, 'fiction': 2935, 'file': 2936, 'flag': 2937, 'flame': 2938, 'flaunt': 2939, 'fluctuate': 2940, 'fluent': 2941, 'fly': 2942, 'forgive': 2943, 'fourth': 2944, 'fracking': 2945, 'freaked': 2946, 'freeing': 2947, 'freeze': 2948, 'freezing': 2949, 'frequent': 2950, 'freshman': 2951, 'fueled': 2952, 'gaining': 2953, 'gathering': 2954, 'gay\\x9d': 2955, 'gendersexuality': 2956, 'generated': 2957, 'generator': 2958, 'genital': 2959, 'george': 2960, 'gid': 2961, 'girli': 2962, 'gladly': 2963, 'glass': 2964, 'gnc': 2965, 'googled': 2966, 'grab': 2967, 'grain': 2968, 'grandpa': 2969, 'grandparent': 2970, 'green': 2971, 'grief': 2972, 'gynaecomastia': 2973, 'hairstyle': 2974, 'hall': 2975, 'happend': 2976, 'happiest': 2977, 'harmed': 2978, 'harming': 2979, 'harsh': 2980, 'heartbeat': 2981, 'heartbreak': 2982, 'heating': 2983, 'heavier': 2984, 'hetero': 2985, 'hethey': 2986, 'heyo': 2987, 'hickey': 2988, 'hid': 2989, 'hint': 2990, 'horizon': 2991, 'horrified': 2992, 'horror': 2993, 'hundred': 2994, 'hydrogen': 2995, 'hyper': 2996, 'hypothetical': 2997, 'ice': 2998, 'ideation': 2999, 'identical': 3000, 'immune': 3001, 'inch': 3002, 'includes': 3003, 'inconvenient': 3004, 'indicate': 3005, 'inevitable': 3006, 'inflation': 3007, 'inform': 3008, 'infuriating': 3009, 'injury': 3010, 'insanely': 3011, 'insensitive': 3012, 'instagram': 3013, 'instance': 3014, 'intended': 3015, 'intercourse': 3016, 'internally': 3017, 'interviewed': 3018, 'involves': 3019, 'involving': 3020, 'ion': 3021, 'irrational': 3022, 'isolated': 3023, 'isolation': 3024, 'iv': 3025, 'jacket': 3026, 'january': 3027, 'jawline': 3028, 'jet': 3029, 'joined': 3030, 'joking': 3031, 'jokingly': 3032, 'joy': 3033, 'july': 3034, 'kick': 3035, 'kicked': 3036, 'killed': 3037, 'kindergarten': 3038, 'kinky': 3039, 'kinsey': 3040, 'knee': 3041, 'knife': 3042, 'knowledgeable': 3043, 'l': 3044, 'labelling': 3045, 'ladder': 3046, 'lanthanide': 3047, 'lastly': 3048, 'laying': 3049, 'layman': 3050, 'lecture': 3051, 'legitimate': 3052, 'legitimately': 3053, 'lens': 3054, 'liberated': 3055, 'lifting': 3056, 'limited': 3057, 'literal': 3058, 'location': 3059, 'longing': 3060, 'longterm': 3061, 'loop': 3062, 'madam': 3063, 'magnet': 3064, 'magnetic': 3065, 'malefemale': 3066, 'manifested': 3067, 'mapped': 3068, 'maria': 3069, 'mascara': 3070, 'masking': 3071, 'measurement': 3072, 'mechanical': 3073, 'melatonin': 3074, 'mentioning': 3075, 'mercury': 3076, 'messaging': 3077, 'methionine': 3078, 'micro': 3079, 'military': 3080, 'misery': 3081, 'misogynistic': 3082, 'misophonia': 3083, 'mixed': 3084, 'monday': 3085, 'monster': 3086, 'monthly': 3087, 'montly': 3088, 'mormon': 3089, 'mutual': 3090, 'nagging': 3091, 'natal': 3092, 'native': 3093, 'nauseous': 3094, 'navigate': 3095, 'nd': 3096, 'negatively': 3097, 'neptune': 3098, 'network': 3099, 'neutrino': 3100, 'news': 3101, 'nitrogen': 3102, 'nonstop': 3103, 'nope': 3104, 'north': 3105, 'nose': 3106, 'notably': 3107, 'nowadays': 3108, 'nude': 3109, 'nut': 3110, 'objectively': 3111, 'obscur': 3112, 'observe': 3113, 'observing': 3114, 'obsessive': 3115, 'occurs': 3116, 'ofc': 3117, 'offend': 3118, 'offends': 3119, 'office': 3120, 'oil': 3121, 'omg': 3122, 'omnisexuality': 3123, 'operating': 3124, 'operation': 3125, 'oral': 3126, 'orchiectomy': 3127, 'ordinary': 3128, 'outfit': 3129, 'outweigh': 3130, 'oversized': 3131, 'painted': 3132, 'panel': 3133, 'pangender': 3134, 'panty': 3135, 'parental': 3136, 'passionate': 3137, 'patch': 3138, 'patriarchy': 3139, 'paying': 3140, 'pear': 3141, 'penetrated': 3142, 'perceives': 3143, 'performance': 3144, 'permission': 3145, 'persona': 3146, 'phantom': 3147, 'phrase': 3148, 'picking': 3149, 'pigtails\\x9d': 3150, 'pissed': 3151, 'pixie': 3152, 'player': 3153, 'plenty': 3154, 'plz': 3155, 'poor': 3156, 'portion': 3157, 'poster': 3158, 'practically': 3159, 'preeverything': 3160, 'preferably': 3161, 'presence': 3162, 'presented': 3163, 'prevent': 3164, 'primarily': 3165, 'principle': 3166, 'prior': 3167, 'privacy': 3168, 'privately': 3169, 'privilage': 3170, 'professor': 3171, 'program': 3172, 'progressed': 3173, 'prom': 3174, 'prospect': 3175, 'providing': 3176, 'psychotherapist': 3177, 'publicly': 3178, 'pulled': 3179, 'pure': 3180, 'pushing': 3181, 'quantum': 3182, 'quiet': 3183, 'quit': 3184, 'raise': 3185, 'rapidly': 3186, 'rate': 3187, 'raw': 3188, 'realistic': 3189, 'realization': 3190, 'reasoning': 3191, 'reassignment': 3192, 'reassure': 3193, 'recall': 3194, 'receive': 3195, 'receiver': 3196, 'receptive': 3197, 'recommend': 3198, 'recording': 3199, 'reduces': 3200, 'reflect': 3201, 'refusing': 3202, 'reject': 3203, 'relaxed': 3204, 'remains': 3205, 'repeat': 3206, 'repeated': 3207, 'replacement': 3208, 'replied': 3209, 'represent': 3210, 'require': 3211, 'resolution': 3212, 'responded': 3213, 'resulting': 3214, 'resurfaced': 3215, 'retrovirus': 3216, 'returned': 3217, 'revelation': 3218, 'ridicule': 3219, 'rlly': 3220, 'road': 3221, 'rooted': 3222, 'rope': 3223, 'roughly': 3224, 'rquestioning': 3225, 'ruined': 3226, 'ruining': 3227, 'rust': 3228, 'sadly': 3229, 'sadness': 3230, 'sandy': 3231, 'scarring': 3232, 'scene': 3233, 'screaming': 3234, 'segregated': 3235, 'sell': 3236, 'semester': 3237, 'semi': 3238, 'sending': 3239, 'senior': 3240, 'sensor': 3241, 'separated': 3242, 'serf': 3243, 'settle': 3244, 'settled': 3245, 'setup': 3246, 'severity': 3247, 'sexgender': 3248, 'shaking': 3249, 'shameful': 3250, 'shattered': 3251, 'shitless': 3252, 'shop': 3253, 'shout': 3254, 'showed': 3255, 'shunned': 3256, 'significantly': 3257, 'simon': 3258, 'sin': 3259, 'singularity': 3260, 'sink': 3261, 'site': 3262, 'skull': 3263, 'slept': 3264, 'slug': 3265, 'sobbing': 3266, 'softer': 3267, 'solve': 3268, 'sometime': 3269, 'soo': 3270, 'sophomore': 3271, 'sour': 3272, 'speech': 3273, 'spelling': 3274, 'sphere': 3275, 'spicy': 3276, 'split': 3277, 'spontaneously': 3278, 'spring': 3279, 'starve': 3280, 'stature': 3281, 'stem': 3282, 'stemmed': 3283, 'storage': 3284, 'storm': 3285, 'strangely': 3286, 'strategy': 3287, 'strictly': 3288, 'strike': 3289, 'studied': 3290, 'stumbled': 3291, 'suggesting': 3292, 'suggests': 3293, 'sun': 3294, 'sunlight': 3295, 'supernova': 3296, 'supposedly': 3297, 'surprised': 3298, 'surrounding': 3299, 'surroundings': 3300, 'surviving': 3301, 'swing': 3302, 'switching': 3303, 'taboo': 3304, 'tackle': 3305, 'tag': 3306, 'tape': 3307, 'teaching': 3308, 'team': 3309, 'telescope': 3310, 'terminology': 3311, 'terribly': 3312, 'testing': 3313, 'theatre': 3314, 'therapeutic': 3315, 'thinner': 3316, 'thong': 3317, 'throwaway': 3318, 'thrown': 3319, 'tide': 3320, 'tightly': 3321, 'tire': 3322, 'toe': 3323, 'toilet': 3324, 'tolerable': 3325, 'toned': 3326, 'torn': 3327, 'torture': 3328, 'touching': 3329, 'transformed': 3330, 'transforming': 3331, 'transgenderism': 3332, 'transgenders': 3333, 'transmasculine': 3334, 'transsexuality': 3335, 'treating': 3336, 'trial': 3337, 'triangle': 3338, 'tricked': 3339, 'triggering': 3340, 'troll': 3341, 'troubling': 3342, 'tuft': 3343, 'turbine': 3344, 'twist': 3345, 'typo': 3346, 'uk': 3347, 'ultimately': 3348, 'um': 3349, 'unacceptable': 3350, 'uncomfy': 3351, 'undercut': 3352, 'understandable': 3353, 'undesirable': 3354, 'united': 3355, 'unlike': 3356, 'unloveable': 3357, 'unlucky': 3358, 'unusual': 3359, 'uranus': 3360, 'useless': 3361, 'vaginal': 3362, 'validated': 3363, 'validates': 3364, 'vary': 3365, 'vector': 3366, 'version': 3367, 'vibrating': 3368, 'victim': 3369, 'viewed': 3370, 'visiting': 3371, 'vomit': 3372, 'wash': 3373, 'waste': 3374, 'wedding': 3375, 'weekly': 3376, 'weirdest': 3377, 'weirdly': 3378, 'whale': 3379, 'whim': 3380, 'width': 3381, 'wight': 3382, 'wing': 3383, 'withdrawal': 3384, 'witness': 3385, 'womanly': 3386, 'wonderful': 3387, 'worded': 3388, 'worker': 3389, 'workshop': 3390, 'wound': 3391, 'wtf': 3392, 'yearning': 3393, 'zika': 3394, 'zoom': 3395, 'ï': 3396, '😁': 3397})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "\n",
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "pBnLkBgMjlu1"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "w2RveHGGjogy"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------Hyperparameters--------------------------"
      ],
      "metadata": {
        "id": "6OOa0F9BeuZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 256\n",
        "num_output_nodes = 1\n",
        "num_layers = 8\n",
        "bidirection = True\n",
        "dropout = 0.3\n",
        "lr = 0.00001\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)"
      ],
      "metadata": {
        "id": "tomzPNlijppI"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "metadata": {
        "id": "pu5KyfxZjrAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278c7a5a-4703-42c0-f1b4-9564c623695b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(3398, 300)\n",
            "  (lstm): LSTM(300, 256, num_layers=8, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 13,201,417 trainable parameters\n",
            "torch.Size([3398, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define optimizer and loss\n",
        "\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(),lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "XETBH7p1jtKp"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YGNa0BR-ymYN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "tYOA55zsju-o"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "G20sxhBMjwex"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 60\n",
        "model_name = 'LSTM'"
      ],
      "metadata": {
        "id": "wKNl_ipyMpmH"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = f'{model_name}_hidden_{num_hidden_nodes}_epochs_{N_EPOCHS}_batch_size{BATCH_SIZE}_lr_{lr}_num_layers{num_layers}_vocab_{vocab}_{optimizer.__class__.__name__}_dropout_{dropout}'"
      ],
      "metadata": {
        "id": "v7ZiH3wsrG6t"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"LGBT\", entity=\"cs519\",name=run_name)\n",
        "wandb.watch(model)"
      ],
      "metadata": {
        "id": "q1R0ah8LMmD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "7b52410fb7974f078f0ffce82f6c2530",
            "583f30bb3bc4412c95f6aec8cf52f2ec",
            "0c9cac3a4e2849cbbe637e87650b2ac3",
            "dd19dfafdf414b19b60acd240a98b090",
            "f393e42a2eae44e3a09f819d2d1511ea",
            "89a6857ad4ee44c5a0bc35d4eb60dfe2",
            "45c6d9e1214149ae9b7361e92b803355",
            "c049f13e18884026be208d6599c2099b"
          ]
        },
        "outputId": "36fe246c-e222-41d2-8f6c-7b937b491d3e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1y3z364x) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b52410fb7974f078f0ffce82f6c2530"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>████████████▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Valid Loss</td><td>████████████▆▅▅▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>49</td></tr><tr><td>Train Loss</td><td>0.19706</td></tr><tr><td>Valid Loss</td><td>0.27346</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">LSTM_hidden_256_epochs_50_batch_size64_lr_1e-05_num_layers8_vocab_glove.840B.300d_AdamW_dropout_0.3</strong>: <a href=\"https://wandb.ai/cs519/LGBT/runs/1y3z364x\" target=\"_blank\">https://wandb.ai/cs519/LGBT/runs/1y3z364x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220423_015050-1y3z364x/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1y3z364x). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220423_023421-3eh7i3pa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs519/LGBT/runs/3eh7i3pa\" target=\"_blank\">LSTM_hidden_256_epochs_60_batch_size64_lr_1e-05_num_layers8_vocab_glove.840B.300d_AdamW_dropout_0.3</a></strong> to <a href=\"https://wandb.ai/cs519/LGBT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    wandb.log({\n",
        "        \"Epoch\": epoch,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Valid Loss\": valid_loss})\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'{run_name}.pt')\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "gTCdgRKFjxn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e243554c-055d-49d5-8827-24871e04d992"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.83%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 2\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.83%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 3\n",
            "\tTrain Loss: 0.693 | Train Acc: 47.63%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 4\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.05%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 5\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.61%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 6\n",
            "\tTrain Loss: 0.693 | Train Acc: 51.14%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 7\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.42%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 8\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.13%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 48.06%\n",
            "Epoch 9\n",
            "\tTrain Loss: 0.693 | Train Acc: 56.16%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 54.37%\n",
            "Epoch 10\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.74%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 54.37%\n",
            "Epoch 11\n",
            "\tTrain Loss: 0.693 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.85%\n",
            "Epoch 12\n",
            "\tTrain Loss: 0.692 | Train Acc: 52.25%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.85%\n",
            "Epoch 13\n",
            "\tTrain Loss: 0.691 | Train Acc: 51.73%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 53.85%\n",
            "Epoch 14\n",
            "\tTrain Loss: 0.685 | Train Acc: 52.25%\n",
            "\t Val. Loss: 0.673 |  Val. Acc: 54.37%\n",
            "Epoch 15\n",
            "\tTrain Loss: 0.663 | Train Acc: 54.11%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 58.54%\n",
            "Epoch 16\n",
            "\tTrain Loss: 0.624 | Train Acc: 66.31%\n",
            "\t Val. Loss: 0.576 |  Val. Acc: 74.69%\n",
            "Epoch 17\n",
            "\tTrain Loss: 0.570 | Train Acc: 74.65%\n",
            "\t Val. Loss: 0.532 |  Val. Acc: 85.31%\n",
            "Epoch 18\n",
            "\tTrain Loss: 0.521 | Train Acc: 83.79%\n",
            "\t Val. Loss: 0.478 |  Val. Acc: 85.65%\n",
            "Epoch 19\n",
            "\tTrain Loss: 0.484 | Train Acc: 85.32%\n",
            "\t Val. Loss: 0.458 |  Val. Acc: 87.24%\n",
            "Epoch 20\n",
            "\tTrain Loss: 0.466 | Train Acc: 84.42%\n",
            "\t Val. Loss: 0.435 |  Val. Acc: 87.04%\n",
            "Epoch 21\n",
            "\tTrain Loss: 0.433 | Train Acc: 85.44%\n",
            "\t Val. Loss: 0.443 |  Val. Acc: 81.89%\n",
            "Epoch 22\n",
            "\tTrain Loss: 0.407 | Train Acc: 85.74%\n",
            "\t Val. Loss: 0.399 |  Val. Acc: 86.29%\n",
            "Epoch 23\n",
            "\tTrain Loss: 0.385 | Train Acc: 86.40%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 86.70%\n",
            "Epoch 24\n",
            "\tTrain Loss: 0.354 | Train Acc: 86.93%\n",
            "\t Val. Loss: 0.371 |  Val. Acc: 84.50%\n",
            "Epoch 25\n",
            "\tTrain Loss: 0.337 | Train Acc: 87.00%\n",
            "\t Val. Loss: 0.367 |  Val. Acc: 84.85%\n",
            "Epoch 26\n",
            "\tTrain Loss: 0.332 | Train Acc: 86.46%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 88.08%\n",
            "Epoch 27\n",
            "\tTrain Loss: 0.314 | Train Acc: 88.74%\n",
            "\t Val. Loss: 0.334 |  Val. Acc: 87.36%\n",
            "Epoch 28\n",
            "\tTrain Loss: 0.307 | Train Acc: 87.74%\n",
            "\t Val. Loss: 0.330 |  Val. Acc: 87.51%\n",
            "Epoch 29\n",
            "\tTrain Loss: 0.292 | Train Acc: 88.16%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 88.81%\n",
            "Epoch 30\n",
            "\tTrain Loss: 0.287 | Train Acc: 88.85%\n",
            "\t Val. Loss: 0.334 |  Val. Acc: 87.16%\n",
            "Epoch 31\n",
            "\tTrain Loss: 0.282 | Train Acc: 89.18%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 89.67%\n",
            "Epoch 32\n",
            "\tTrain Loss: 0.282 | Train Acc: 89.41%\n",
            "\t Val. Loss: 0.308 |  Val. Acc: 89.33%\n",
            "Epoch 33\n",
            "\tTrain Loss: 0.271 | Train Acc: 89.27%\n",
            "\t Val. Loss: 0.299 |  Val. Acc: 89.85%\n",
            "Epoch 34\n",
            "\tTrain Loss: 0.264 | Train Acc: 89.85%\n",
            "\t Val. Loss: 0.308 |  Val. Acc: 88.81%\n",
            "Epoch 35\n",
            "\tTrain Loss: 0.259 | Train Acc: 90.15%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 89.33%\n",
            "Epoch 36\n",
            "\tTrain Loss: 0.259 | Train Acc: 89.78%\n",
            "\t Val. Loss: 0.302 |  Val. Acc: 88.98%\n",
            "Epoch 37\n",
            "\tTrain Loss: 0.251 | Train Acc: 90.83%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 90.57%\n",
            "Epoch 38\n",
            "\tTrain Loss: 0.250 | Train Acc: 90.30%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 88.46%\n",
            "Epoch 39\n",
            "\tTrain Loss: 0.243 | Train Acc: 90.42%\n",
            "\t Val. Loss: 0.285 |  Val. Acc: 90.40%\n",
            "Epoch 40\n",
            "\tTrain Loss: 0.238 | Train Acc: 90.97%\n",
            "\t Val. Loss: 0.288 |  Val. Acc: 89.50%\n",
            "Epoch 41\n",
            "\tTrain Loss: 0.232 | Train Acc: 91.08%\n",
            "\t Val. Loss: 0.280 |  Val. Acc: 90.60%\n",
            "Epoch 42\n",
            "\tTrain Loss: 0.228 | Train Acc: 91.38%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 90.02%\n",
            "Epoch 43\n",
            "\tTrain Loss: 0.227 | Train Acc: 91.08%\n",
            "\t Val. Loss: 0.275 |  Val. Acc: 90.77%\n",
            "Epoch 44\n",
            "\tTrain Loss: 0.219 | Train Acc: 91.34%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 88.63%\n",
            "Epoch 45\n",
            "\tTrain Loss: 0.218 | Train Acc: 91.82%\n",
            "\t Val. Loss: 0.276 |  Val. Acc: 89.88%\n",
            "Epoch 46\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.90%\n",
            "\t Val. Loss: 0.274 |  Val. Acc: 89.50%\n",
            "Epoch 47\n",
            "\tTrain Loss: 0.209 | Train Acc: 91.82%\n",
            "\t Val. Loss: 0.270 |  Val. Acc: 90.45%\n",
            "Epoch 48\n",
            "\tTrain Loss: 0.208 | Train Acc: 92.19%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.36%\n",
            "Epoch 49\n",
            "\tTrain Loss: 0.203 | Train Acc: 92.27%\n",
            "\t Val. Loss: 0.271 |  Val. Acc: 90.05%\n",
            "Epoch 50\n",
            "\tTrain Loss: 0.198 | Train Acc: 92.34%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 90.45%\n",
            "Epoch 51\n",
            "\tTrain Loss: 0.199 | Train Acc: 92.05%\n",
            "\t Val. Loss: 0.279 |  Val. Acc: 89.01%\n",
            "Epoch 52\n",
            "\tTrain Loss: 0.195 | Train Acc: 92.57%\n",
            "\t Val. Loss: 0.274 |  Val. Acc: 89.70%\n",
            "Epoch 53\n",
            "\tTrain Loss: 0.188 | Train Acc: 92.64%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 90.08%\n",
            "Epoch 54\n",
            "\tTrain Loss: 0.182 | Train Acc: 93.12%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 91.50%\n",
            "Epoch 55\n",
            "\tTrain Loss: 0.184 | Train Acc: 92.97%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 88.49%\n",
            "Epoch 56\n",
            "\tTrain Loss: 0.185 | Train Acc: 92.90%\n",
            "\t Val. Loss: 0.254 |  Val. Acc: 91.18%\n",
            "Epoch 57\n",
            "\tTrain Loss: 0.179 | Train Acc: 93.53%\n",
            "\t Val. Loss: 0.255 |  Val. Acc: 91.35%\n",
            "Epoch 58\n",
            "\tTrain Loss: 0.187 | Train Acc: 93.24%\n",
            "\t Val. Loss: 0.256 |  Val. Acc: 91.15%\n",
            "Epoch 59\n",
            "\tTrain Loss: 0.173 | Train Acc: 93.53%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.53%\n",
            "Epoch 60\n",
            "\tTrain Loss: 0.167 | Train Acc: 93.27%\n",
            "\t Val. Loss: 0.262 |  Val. Acc: 91.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights\n",
        "path=f'{run_name}.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "\n",
        "#inference \n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
        "    length = [len(indexed)]                                    #compute no. of words\n",
        "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
        "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
        "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
        "    prediction = model(tensor, length_tensor)                  #prediction \n",
        "    return prediction.item()         "
      ],
      "metadata": {
        "id": "UIC6uMfajzi-"
      },
      "execution_count": 108,
      "outputs": []
    }
  ]
}